{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the instances from Taillard (1989)\n",
    "def read_instances_from_file(filename):\n",
    "    \"\"\"Read and parse multiple Flowshop instances from a text file, extracting the processing times and lower bound.\"\"\"\n",
    "    times = []\n",
    "    machines = []\n",
    "    lower_bounds = []\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            if lines[i].startswith(\"Nb of jobs\"):\n",
    "                parts = list(map(int, lines[i + 1].split()))\n",
    "                num_jobs, num_machines, _, _,_, lower_bound = parts\n",
    "                lower_bounds.append(lower_bound)\n",
    "                i += 3  # Move to processing times\n",
    "                processing_times = []\n",
    "                for _ in range(num_jobs):\n",
    "                    processing_times.append(list(map(int, lines[i].split())))\n",
    "                    i += 1\n",
    "                times.append(np.array(processing_times))\n",
    "                i+=1\n",
    "                machines_i=[]\n",
    "                for _ in range(num_jobs):\n",
    "                    machines_i.append(list(map(int, lines[i].split())))\n",
    "                    i += 1\n",
    "                machines.append(np.array(machines_i))\n",
    "                \n",
    "            else:\n",
    "                i += 1\n",
    "    return times, machines, lower_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed804cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base scenario (first instance of the 15 jobs x 15 machines)\n",
    "t_all,m_all,lb_all=read_instances_from_file(\"tai15_15.txt\")\n",
    "times1=t_all[0]\n",
    "machines1=m_all[0]\n",
    "lb1=lb_all[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789f983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create the \"schedule\" - Evaluate fitness (makespan, initial_times, end_times)\n",
    "def evaluate_fitness(schedule, times, machines):\n",
    "    #Properties of the JSSP analyzed\n",
    "    n_jobs, n_ops = times.shape\n",
    "    #number of machines(as it is 0-indexed, +1 to adjust the numbering)\n",
    "    n_machines = np.max(machines)+1 \n",
    "    #Array to store the current machine operation end time\n",
    "    machine_available = [0] * n_machines\n",
    "    #array to store the current job operation end time\n",
    "    job_next_op = [0] * n_jobs\n",
    "    #array to store the current job end time\n",
    "    job_available = [0] * n_jobs\n",
    "    op_start_times = {}\n",
    "    op_end_times = {}\n",
    "    #Set to store the assigend operations\n",
    "    processed = set()\n",
    "    \n",
    "    while len(processed) < n_jobs * n_ops:\n",
    "        for job_id, op_id in schedule:\n",
    "            #If the operation has been scheduled, next item in the schedule and it is not assigned.\n",
    "            if (job_id, op_id) in processed:\n",
    "                continue\n",
    "            #if the operation analyzed in the schedule is not the last registered\n",
    "            if op_id != job_next_op[job_id]:\n",
    "                continue\n",
    "\n",
    "            #get the machine number\n",
    "            machine = machines[job_id][op_id]\n",
    "            #identify which is the earliest time for scheduling: after the machine is free or after the previous activity of the job is finished\n",
    "            start_time = max(machine_available[machine], job_available[job_id])\n",
    "            #start_time = machine_available[machine]\n",
    "            #get the operation duration\n",
    "            duration = times[job_id][op_id]\n",
    "            #update the end time\n",
    "            end_time = start_time + duration\n",
    "            #update the earliest time for the machine to be assigned\n",
    "            machine_available[machine] = end_time\n",
    "            #update the earliest time for the job to be resumed\n",
    "            job_available[job_id] = end_time\n",
    "            #update the number of operations that has been assigned in the job\n",
    "            job_next_op[job_id] += 1\n",
    "            #update the start time of all operations for the jobs and machines\n",
    "            op_start_times[(job_id, op_id)] = start_time\n",
    "            #update the end time of all operations for the jobs and machines\n",
    "            op_end_times[(job_id, op_id)] = end_time\n",
    "            #marks the operation/job as assigned\n",
    "            processed.add((job_id, op_id))\n",
    "    makespan = max(op_end_times.values()) if op_end_times else float('inf')\n",
    "    return makespan, op_start_times, op_end_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01d5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54746525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust the numebring of machines to be 0 starting index\n",
    "machines1-=1\n",
    "n_jobs1, n_ops1 = times1.shape\n",
    "n_machines1 = np.max(machines1)+1\n",
    "\n",
    "#initial schedule (setting in order as originally from the instance. First job, then second and so forth)\n",
    "schedule_i=[]\n",
    "for j in range (n_jobs1):\n",
    "    for o in machines1[j]:\n",
    "        schedule_i.append((j,o))\n",
    "\n",
    "makespan1, op_start_times1, op_end_times1 = evaluate_fitness(schedule_i, times1, machines1)\n",
    "print(\"Makespan Basic Assignation:\", makespan1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_schedule(schedule, op_start_times, op_end_times,machines):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    colors = cm.get_cmap('tab20', machines.shape[0])\n",
    "    job_labels = []\n",
    "    job_colors = []\n",
    "    for (job, op) in schedule:\n",
    "        # if job==0:\n",
    "        key = (job, op)\n",
    "        if key not in op_start_times:\n",
    "            continue\n",
    "\n",
    "        machine = machines[job][op] +1\n",
    "        start = op_start_times[key]\n",
    "        end = op_end_times[key]\n",
    "        color = colors(job)\n",
    "        \n",
    "        ax.barh(machine, end - start, left=start, edgecolor='black', color=color)\n",
    "        # ax.text(start + (end - start)/2, machine, f'J{job}-O{op}',\n",
    "        #         ha='center', va='center', color='white', fontsize=7)\n",
    "\n",
    "        if job not in job_labels:\n",
    "            job_labels.append(job)\n",
    "            job_colors.append(color)\n",
    "\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine')\n",
    "    ax.set_yticks(range(1,np.max(machines)+1+1,1))\n",
    "    ax.set_title('Gantt Chart')\n",
    "    ax.legend([plt.Rectangle((0,0),1,1, color=c) for c in job_colors],\n",
    "              [f\"Job {j+1}\" for j in job_labels],\n",
    "              loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Machine')\n",
    "    # ax.set_yticks(range(1,np.max(machines)+1,1))\n",
    "    ax.set_title('Gantt Chart')\n",
    "    ax.legend([f\"Job {j+1}\" for j in range(machines.shape[0])], loc='upper center', bbox_to_anchor=(0.5, -0.5), ncol=5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee61b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0df6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_schedule(schedule_i, op_start_times1, op_end_times1,machines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c850c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial constructive heuristic\n",
    "#based on priorizing (job,ops) based on the longest jobs to perform\n",
    "def most_work_remaining_initialization(times, machines):\n",
    "    n_jobs, n_ops = times.shape\n",
    "    job_next_op = [0] * n_jobs #Stores the number of operations assigned per job\n",
    "    job_available = [0] * n_jobs #Stores the end time for each job\n",
    "    machine_available = [0] * (np.max(machines)+1) #Stores the end time for each machine\n",
    "    schedule = []\n",
    "\n",
    "    remaining = True\n",
    "    while remaining:\n",
    "        ready_ops = []\n",
    "        for j in range(n_jobs):\n",
    "            o = job_next_op[j]\n",
    "            if o < n_ops:\n",
    "                remaining_work = sum(times[j][o:]) #calculates the total processing time of Job j\n",
    "                m = machines[j][o] \n",
    "                earliest_start = max(job_available[j], machine_available[m]) #identifies if the activity must be placed after machine is empty or after the previous op of the job is done\n",
    "                ready_ops.append((-remaining_work, earliest_start, j, o))\n",
    "\n",
    "        if not ready_ops:\n",
    "            break\n",
    "\n",
    "        ready_ops.sort()  #Sorts based on the processing time\n",
    "        _, _, j, o = ready_ops[0]\n",
    "\n",
    "        schedule.append((j, o))\n",
    "        m = machines[j][o] \n",
    "        start_time = max(job_available[j], machine_available[m]) #identifies if the activity must be placed after machine is empty or after the previous op of the job is done\n",
    "        end_time = start_time + times[j][o]\n",
    "        job_available[j] = end_time\n",
    "        machine_available[m] = end_time\n",
    "        job_next_op[j] += 1\n",
    "\n",
    "        remaining = any(op < n_ops for op in job_next_op)\n",
    "\n",
    "    return schedule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule1x = most_work_remaining_initialization(times1, machines1)\n",
    "makespan1x, start_times1x, end_times1x = evaluate_fitness(schedule1x, times1, machines1)\n",
    "print(\"Makespan Constructive Heuristic Assignation:\",makespan1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_schedule(schedule1x, start_times1x, end_times1x,machines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ec67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# DESTRUCTION METHODS\n",
    "# ------------------------\n",
    "\n",
    "#random destruction\n",
    "def destroy_random(scheduleD, pct,n_jobs,n_machines,machines,times):\n",
    "    k = int(len(scheduleD) * pct)\n",
    "    removal_indices = random.sample(range(len(scheduleD)), k)\n",
    "    #returns the list except the items (jobs,ops) corresponding to the k values non considered\n",
    "    return [op for i, op in enumerate(scheduleD) if i not in removal_indices]\n",
    "\n",
    "#Worst individual processing time destruction\n",
    "def destroy_worst_duration(scheduleD, start_times, end_times, pct,n_jobs,n_machines,machines,times):\n",
    "    k = int(len(scheduleD) * pct)\n",
    "    #calculates the processing time of the pair (job,op)\n",
    "    process_t = [(op, end_times[op] - start_times[op]) for op in scheduleD if op in end_times]\n",
    "    #sorts the list in descending order\n",
    "    sorted_ops = sorted(process_t, key=lambda x: -x[1])\n",
    "    #removes the k elements with the longest processing times\n",
    "    to_remove = set(op for op, _ in sorted_ops[:k])\n",
    "    return [op for op in scheduleD if op not in to_remove]\n",
    "\n",
    "#Random block destruction\n",
    "def destroy_block(scheduleD, pct,n_jobs,n_machines,machines,times):\n",
    "    k = int(len(scheduleD) * pct)\n",
    "    #random location to remove the k elements\n",
    "    start = random.randint(0, len(scheduleD) - k)\n",
    "    return scheduleD[:start] + scheduleD[start + k:]\n",
    "\n",
    "# Worst idling time element destruction\n",
    "def destroy_worst_idle(scheduleD, start_times, end_times, pct,n_jobs,n_machines,machines,times):\n",
    "    k = int(len(scheduleD) * pct)\n",
    "    idles = []\n",
    "    #stores the moment when a new job can start\n",
    "    job_ready = [0] * n_jobs\n",
    "    #stores the moment when each machine can theorically start \n",
    "    machine_ready = [0] * n_machines\n",
    "    for (j, o) in scheduleD:\n",
    "        m = machines[j][o]-1\n",
    "\n",
    "        #theorical earliest start\n",
    "        earliest_start = max(job_ready[j], machine_ready[m])\n",
    "        actual_start = start_times.get((j, o), float('inf'))\n",
    "        idle = actual_start - earliest_start\n",
    "        idles.append(((j, o), idle))\n",
    "\n",
    "        #update availability for simulation purposes\n",
    "        job_ready[j] = actual_start + times[j][o]\n",
    "        machine_ready[m] = actual_start + times[j][o]\n",
    "\n",
    "    #sorts in descending order and removes the k elemnts with the largest idling times\n",
    "    sorted_ops = sorted(idles, key=lambda x: -x[1])\n",
    "    to_remove = set(op for op, _ in sorted_ops[:k])\n",
    "    return [op for op in scheduleD if op not in to_remove]\n",
    "\n",
    "\n",
    "# Highest used machine activity destruction\n",
    "def destroy_machine_time(scheduleD, pct,n_jobs,n_machines,machines,times):\n",
    "    #processing times for each machine\n",
    "    time_i = [0] * n_machines\n",
    "    #stores all the combiantion of (job,operation) that is processed in machine \"m\"\n",
    "    machine_to_ops = {m: [] for m in range(n_machines)}\n",
    "    #iterates over the pairs (job,ops) to sum over the machines the processing times\n",
    "    for job_id, op_id in scheduleD:\n",
    "        #Sets the machine to add the processing time\n",
    "        machine = machines[job_id][op_id]\n",
    "        time_i[machine] += times[job_id][op_id]\n",
    "        machine_to_ops[machine].append((job_id, op_id))\n",
    "\n",
    "    #defines the machine with the most work\n",
    "    max_load_machine = np.argmax(time_i)\n",
    "    #sets the list of operations that belong to the busiest machine\n",
    "    ops_on_machine = machine_to_ops[max_load_machine]\n",
    "\n",
    "    k = int(len(scheduleD) * pct)\n",
    "    #removes the k-elements from the most used machine\n",
    "    to_remove = set(random.sample(ops_on_machine, min(k, len(ops_on_machine))))\n",
    "    return [op for op in scheduleD if op not in to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d28657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# REPAIR METHODS\n",
    "# ------------------------\n",
    "\n",
    "#Shortest Processing times \n",
    "def repair_spt(scheduleR,n_jobs,n_machines,machines,times):\n",
    "    remaining_ops = [(j, o) for j in range(n_jobs) for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "    #the remaining ops from the corresponding jobs are scheduled based on the shortest processing times \n",
    "    # at the end of the schedule\n",
    "    remaining_ops.sort(key=lambda x: times[x[0]][x[1]])\n",
    "    return scheduleR + remaining_ops\n",
    "\n",
    "#Random Order\n",
    "def repair_random(scheduleR,n_jobs,n_machines,machines,times):\n",
    "    remaining_ops = [(j, o) for j in range(n_jobs) for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "    random.shuffle(remaining_ops)\n",
    "    #the remaining ops from the corresponding jobs are scheduled randomly\n",
    "    # at the end of the schedule\n",
    "    return scheduleR + remaining_ops\n",
    "\n",
    "#adds the removed sequence in a random order\n",
    "def repair_random_insert(scheduleR,n_jobs,n_machines,machines,times):\n",
    "    remaining_ops = [(j, o) for j in range(n_jobs) for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "    # for the elemtns not in the list, inserts them in a random location\n",
    "    for op in remaining_ops:\n",
    "        idx = random.randint(0, len(scheduleR))\n",
    "        scheduleR.insert(idx, op)\n",
    "    return scheduleR\n",
    "\n",
    "#Most Work Remaining\n",
    "def repair_mwr(scheduleR,n_jobs,n_machines,machines,times):\n",
    "    remaining_jobs = {}\n",
    "    #calculates the time required to process a complete job\n",
    "    for j in range(n_jobs):\n",
    "        remaining = [(j, o) for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "        if remaining:\n",
    "            remaining_jobs[j] = sum(times[j][o] for _, o in remaining)\n",
    "    #gets the job that has the most time pending to process and sorts the list accordingly\n",
    "    ordered_jobs = sorted(remaining_jobs.items(), key=lambda x: -x[1])\n",
    "    #adds the pending (job,ops) pairs based on the job priorization\n",
    "    ordered_ops = [(j, o) for j, _ in ordered_jobs for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "    return scheduleR + ordered_ops\n",
    "\n",
    "\n",
    "#Most Frequent Machine First\n",
    "def repair_mfmf(scheduleR,n_jobs,n_machines,machines,times):\n",
    "    remaining_ops = [(j, o) for j in range(n_jobs) for o in range(times.shape[1]) if (j, o) not in scheduleR]\n",
    "    machine_freq = {}\n",
    "    #calculates the number of repetitions that each machine ahs in the pending to be assigned elements of the list\n",
    "    for j, o in remaining_ops:\n",
    "        m = machines[j][o] - 1\n",
    "        machine_freq[m] = machine_freq.get(m, 0) +1\n",
    "    #identifies the machines that are needed the most within the pending (job,ops)\n",
    "    sorted_machines = sorted(machine_freq.items(), key=lambda x: -x[1])\n",
    "    ordered_ops = []\n",
    "    #adds the schedule at the end of the previous schedule based on priorizing the assignation of the machine that\n",
    "    #has the largest pending work\n",
    "    for m, _ in sorted_machines:\n",
    "        machine_ops = [(j, o) for j, o in remaining_ops if machines[j][o] - 1 == m]\n",
    "        ordered_ops.extend(machine_ops)\n",
    "    return scheduleR + ordered_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff14dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection for the destroy/repair method based on roulette approach\n",
    "def roulette_select(weights):\n",
    "    total = sum(weights)\n",
    "    pick = random.uniform(0, total)\n",
    "    current = 0\n",
    "    for i, w in enumerate(weights):\n",
    "        current += w\n",
    "        if current >= pick:\n",
    "            return i\n",
    "    return len(weights) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADaptive Large Neighbourhood Search (modified with a Taboo list and a dybnamic assignation of exploration parameters: % of destruction and lambda)\n",
    "def alns(schedule_input, times, machines, iterations, pct_destroy,lambda_a,taboo_tenure,cooling_rate,max_iter_n):\n",
    "    destroy_ops = [destroy_random, destroy_block, destroy_machine_time,destroy_worst_duration, destroy_worst_idle]\n",
    "    repair_ops = [repair_spt, repair_mwr, repair_random, repair_mfmf,repair_random_insert]\n",
    "    pct=pct_destroy\n",
    "    d_weights = [1.0] * len(destroy_ops)\n",
    "    r_weights = [1.0] * len(repair_ops)\n",
    "    psi = [10, 5, 1, 0.1]  # Reward values for: better than global, better than current, accepted worse, rejected worse\n",
    "    best_schedule = list(schedule_input)\n",
    "    schedule=list(schedule_input)\n",
    "    best_makespan, _, _ = evaluate_fitness(best_schedule,times,machines)\n",
    "    d_idx = roulette_select(d_weights)\n",
    "    r_idx = roulette_select(r_weights)\n",
    "\n",
    "    n_jobs=times.shape[0]\n",
    "    n_machines=np.max(machines)+1\n",
    "\n",
    "    taboo_list = []\n",
    "    no_improve_counter = 0\n",
    "    # i=0\n",
    "    for i in range (iterations):\n",
    "        # print(\"Current iteration\",i)\n",
    "        d_idx = roulette_select(d_weights)\n",
    "        r_idx = roulette_select(r_weights)\n",
    "\n",
    "        destroy = destroy_ops[d_idx]\n",
    "        repair = repair_ops[r_idx]\n",
    "\n",
    "        current_makespan, start_times, end_times = evaluate_fitness(schedule,times,machines)\n",
    "        destroyed = destroy(schedule, pct_destroy,n_jobs,n_machines,machines,times) if 'start_times' not in destroy.__code__.co_varnames else destroy(schedule, start_times, end_times, pct_destroy,n_jobs,n_machines,machines,times)\n",
    "        new_schedule = repair(destroyed,n_jobs,n_machines,machines,times)        \n",
    "        new_makespan, _, _ = evaluate_fitness(new_schedule,times,machines)\n",
    "\n",
    "\n",
    "        if new_makespan < best_makespan:\n",
    "            best_schedule = list(new_schedule)\n",
    "            best_makespan = new_makespan\n",
    "            d_weights[d_idx] = lambda_a*d_weights[d_idx]+ (1-lambda_a)*psi[0]\n",
    "            r_weights[r_idx] = lambda_a*r_weights[r_idx]+ (1-lambda_a)*psi[0]\n",
    "            no_improve_counter = 0\n",
    "\n",
    "        elif new_makespan < current_makespan:\n",
    "            d_weights[d_idx] = lambda_a*d_weights[d_idx]+ (1-lambda_a)*psi[1]\n",
    "            r_weights[r_idx] = lambda_a*r_weights[r_idx]+ (1-lambda_a)*psi[1]\n",
    "            schedule = new_schedule\n",
    "            no_improve_counter = 0\n",
    "        else:\n",
    "            accept_prob = 0.1\n",
    "            if random.random() < accept_prob:\n",
    "                d_weights[d_idx] = lambda_a*d_weights[d_idx]+ (1-lambda_a)*psi[2]\n",
    "                r_weights[r_idx] = lambda_a*r_weights[r_idx]+ (1-lambda_a)*psi[2]\n",
    "                schedule = new_schedule\n",
    "            else:\n",
    "                d_weights[d_idx] = lambda_a*d_weights[d_idx]+ (1-lambda_a)*psi[3]\n",
    "                r_weights[r_idx] = lambda_a*r_weights[r_idx]+ (1-lambda_a)*psi[3]\n",
    "            no_improve_counter += 1\n",
    "\n",
    "        taboo_list.append(schedule)\n",
    "        #Keeps the length of tabu list under the parameter tabu_tenure\n",
    "        if len(taboo_list)>taboo_tenure:\n",
    "            taboo_list.pop(0) #removes the oldest value to keep |T|=tabu_tenure\n",
    "\n",
    "\n",
    "        if no_improve_counter >= max_iter_n:\n",
    "            lambda_a /= cooling_rate\n",
    "            pct = min(pct+(1-cooling_rate),1.0)\n",
    "\n",
    "    return best_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c702359",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "iterations=5000\n",
    "pct_destroy=0.2\n",
    "lambda_a=0.8\n",
    "taboo_tenure=50\n",
    "cooling_rate=1.01\n",
    "max_iter_n=100\n",
    "scheduleopt = alns(schedule1x, times1, machines1,iterations,pct_destroy,lambda_a,taboo_tenure,cooling_rate,max_iter_n)\n",
    "makespan, start_times, end_times = evaluate_fitness(scheduleopt,times1,machines1)\n",
    "print(f\"Best Makespan after ALNS optimization: {makespan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_schedule(scheduleopt, start_times, end_times,machines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39142c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa775c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_files=[\"tai15_15.txt\"]#,\"tai20_15.txt\",\"tai20_20.txt\",\"tai30_15.txt\",\"tai30_20.txt\",\n",
    "                # \"tai50_15.txt\",\"tai50_20.txt\",\"tai100_20.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de406bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_iterations=[5000]\n",
    "p_pct_destroy=[0.2]\n",
    "p_lambda_a=[0.8]\n",
    "p_taboo_tenure=[10]\n",
    "p_cooling_rate=[1.01]\n",
    "p_max_iter_n=[100]\n",
    "\n",
    "# Results of the Fitness function\n",
    "makespan_results = []\n",
    "\n",
    "# Schedules\n",
    "schedule_results = []\n",
    "idx_e=0\n",
    "for iterations in p_iterations:\n",
    "    for pct_destroy in p_pct_destroy:\n",
    "        for lambda_a in p_lambda_a:\n",
    "            for taboo_tenure in p_taboo_tenure:\n",
    "                for cooling_rate in p_cooling_rate:\n",
    "                    for max_iter_n in p_max_iter_n:\n",
    "\n",
    "                        for inst, filename in enumerate(instance_files):\n",
    "                            t_ins_i,m_all_i,_=read_instances_from_file(instance_files[inst])\n",
    "                            for iter in range(len(t_ins_i)):\n",
    "                                times=t_ins_i[iter]\n",
    "                                machines=m_all_i[iter]\n",
    "                                machines-=1\n",
    "                                n_jobs, n_machines = times.shape\n",
    "                                instance_name = f\"{filename} - Instance {iter+1}\"\n",
    "                                print(instance_name)\n",
    "                                \n",
    "                                idx_e+=1\n",
    "                                print (f'Progress: {round(idx_e/(len(t_ins_i)*len(instance_files)*len(p_iterations)*len(p_pct_destroy)*len(p_lambda_a)*len(p_taboo_tenure)*len(p_cooling_rate)*len(p_max_iter_n))*100,0)}%')\n",
    "\n",
    "                                #adjust the numbering of machines to be 0 starting index\n",
    "                                t_i=time.time()\n",
    "                                schedule_it= most_work_remaining_initialization(times,machines)\n",
    "                                makespan0, _, _ = evaluate_fitness(schedule_it,times,machines)\n",
    "\n",
    "                                scheduleopt = alns(schedule_it, times, machines,iterations,pct_destroy,lambda_a,taboo_tenure,cooling_rate,max_iter_n)\n",
    "                                makespan, start_times, end_times = evaluate_fitness(scheduleopt,times,machines)\n",
    "                                t_f=time.time()-t_i\n",
    "                                print(makespan)\n",
    "                                # Save makespan data\n",
    "                                makespan_results.append({\n",
    "                                    \"Instance\": instance_name,\n",
    "                                    \"n_jobs\": n_jobs,\n",
    "                                    \"n_machines\": n_machines,\n",
    "                                    \"p_iterations\": iterations,\n",
    "                                    \"p_pct\": pct_destroy,\n",
    "                                    \"p_lambda\": lambda_a,\n",
    "                                    \"p_tabootenure\": taboo_tenure,\n",
    "                                    \"p_cooling_r\": cooling_rate,\n",
    "                                    \"p_max_iters_nomejor\": max_iter_n,\n",
    "                                    \"Initial Makespan\": makespan0,\n",
    "                                    \"Optimized Makespan\": makespan,\n",
    "                                    \"Time (s)\":t_f\n",
    "                                })\n",
    "\n",
    "\n",
    "# Exportar a CSV\n",
    "df_makespan = pd.DataFrame(makespan_results)\n",
    "\n",
    "df_makespan.to_csv(\"results_makespanSA110.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
