{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6a2e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "import math \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82faca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilma\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar archivo Excel\n",
    "file_path = \"generic_input_case.xlsx\"\n",
    "\n",
    "# Leer cada hoja\n",
    "df_horizonte = pd.read_excel(file_path, sheet_name=\"HORIZONTE\")\n",
    "df_bd_up = pd.read_excel(file_path, sheet_name=\"BD_UP\")\n",
    "df_frota = pd.read_excel(file_path, sheet_name=\"FROTA\")\n",
    "df_grua = pd.read_excel(file_path, sheet_name=\"GRUA\")\n",
    "df_fabrica = pd.read_excel(file_path, sheet_name=\"FABRICA\")\n",
    "df_rota = pd.read_excel(file_path, sheet_name=\"ROTA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c42fd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Funciones de Validación de Restricciones ---\n",
    "\n",
    "def validate_daily_demand(schedule_df, df_fabrica,flag):\n",
    "    \"\"\"Verifica si el volumen diario entregado está dentro de los límites.\"\"\"\n",
    "    daily_volume = schedule_df.groupby('DIA')['VOLUME'].sum()\n",
    "    merged = pd.merge(daily_volume.reset_index(), df_fabrica[['DIA', 'DEMANDA_MIN', 'DEMANDA_MAX']], on='DIA')\n",
    "\n",
    "    violations = merged[\n",
    "        (merged['VOLUME'] < merged['DEMANDA_MIN']) |\n",
    "        (merged['VOLUME'] > merged['DEMANDA_MAX'])\n",
    "    ]\n",
    "\n",
    "    if not violations.empty:\n",
    "        if flag==1:\n",
    "            print(\"Incumplimiento - Demanda Diaria:\")\n",
    "            print(violations)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_daily_rsp(schedule_df, df_fabrica,flag):\n",
    "    \"\"\"Verifica si el RSP promedio ponderado diario está dentro de los límites.\"\"\"\n",
    "    if schedule_df.empty or 'VOLUME' not in schedule_df.columns or 'RSP' not in schedule_df.columns:\n",
    "        return True # No hay datos para validar\n",
    "\n",
    "    schedule_df['RSP_WEIGHTED_SUM'] = schedule_df['RSP'] * schedule_df['VOLUME']\n",
    "    daily_rsp_sum = schedule_df.groupby('DIA')['RSP_WEIGHTED_SUM'].sum()\n",
    "    daily_volume_sum = schedule_df.groupby('DIA')['VOLUME'].sum()\n",
    "\n",
    "    # Evitar división por cero si un día no tiene volumen\n",
    "    daily_avg_rsp = (daily_rsp_sum / daily_volume_sum).fillna(0).reset_index()\n",
    "    daily_avg_rsp.rename(columns={0: 'RSP_AVG'}, inplace=True)\n",
    "\n",
    "    merged = pd.merge(daily_avg_rsp, df_fabrica[['DIA', 'RSP_MIN', 'RSP_MAX']], on='DIA')\n",
    "\n",
    "    # Añadir tolerancia pequeña para comparaciones de punto flotante\n",
    "    tolerance = 1e-6\n",
    "    violations = merged[\n",
    "        (round(merged['RSP_AVG'],2) < round(merged['RSP_MIN'],2)) |\n",
    "        (round(merged['RSP_AVG'],2) > round(merged['RSP_MAX'],2))\n",
    "    ]\n",
    "     # Limpiar columna auxiliar\n",
    "    # schedule_df.drop(columns=['RSP_WEIGHTED_SUM'], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "    if not violations.empty:\n",
    "        if flag==1:\n",
    "            print(\"Incumplimiento - RSP Diario:\")\n",
    "            print(violations)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_transporter_fleet_size(schedule_df, df_frota):\n",
    "    \"\"\"Verifica si la flota diaria por transportador está dentro de los límites.\"\"\"\n",
    "    # Asegúrate de contar vehículos únicos por transportador y día\n",
    "    daily_fleet = schedule_df.groupby(['DIA', 'TRANSPORTADOR'])['QTD_VEICULOS'].sum().reset_index() # Suma todos los vehiculos asignados por transportador en el día. OJO: esto asume que QTD_VEICULOS es el total por asignación UP-Transp-Dia\n",
    "\n",
    "    # Necesitamos comparar contra FROTA_MIN y FROTA_MAX por transportador\n",
    "    # df_frota no tiene DIA, se aplica a todos los días\n",
    "    merged = pd.merge(daily_fleet, df_frota[['TRANSPORTADOR', 'FROTA_MIN', 'FROTA_MAX']], on='TRANSPORTADOR')\n",
    "\n",
    "    violations = merged[\n",
    "        (merged['QTD_VEICULOS'] < merged['FROTA_MIN']) |\n",
    "        (merged['QTD_VEICULOS'] > merged['FROTA_MAX'])\n",
    "    ]\n",
    "\n",
    "    if not violations.empty:\n",
    "        print(\"Incumplimiento - Tamaño Flota Transportador:\")\n",
    "        print(violations)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_crane_capacity(schedule_df, df_grua):\n",
    "    \"\"\"Verifica si un transportador atiende más UPs simultáneas que sus grúas.\"\"\"\n",
    "    # Contar UPs únicas atendidas por cada transportador cada día\n",
    "    daily_up_count = schedule_df.groupby(['DIA', 'TRANSPORTADOR'])['UP'].nunique().reset_index()\n",
    "    daily_up_count.rename(columns={'UP': 'UP_COUNT'}, inplace=True)\n",
    "\n",
    "    merged = pd.merge(daily_up_count, df_grua[['TRANSPORTADOR', 'QTD_GRUAS']], on='TRANSPORTADOR')\n",
    "\n",
    "    violations = merged[merged['UP_COUNT'] > merged['QTD_GRUAS']]\n",
    "\n",
    "    if not violations.empty:\n",
    "        print(\"Incumplimiento - Capacidad Grúas:\")\n",
    "        print(violations)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_fazenda_exclusivity(schedule_df):\n",
    "    \"\"\"Verifica si un transportador opera en más de una Fazenda por día.\"\"\"\n",
    "    daily_fazenda_count = schedule_df.groupby(['DIA', 'TRANSPORTADOR'])['FAZENDA'].nunique().reset_index()\n",
    "    daily_fazenda_count.rename(columns={'FAZENDA': 'FAZENDA_COUNT'}, inplace=True)\n",
    "\n",
    "    violations = daily_fazenda_count[daily_fazenda_count['FAZENDA_COUNT'] > 1]\n",
    "\n",
    "    if not violations.empty:\n",
    "        print(\"Incumplimiento - Exclusividad Fazenda:\")\n",
    "        print(violations)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def validate_min_vehicles_per_up(schedule_df, df_grua):\n",
    "    \"\"\"Verifica el porcentaje mínimo de vehículos asignados a una UP.\"\"\"\n",
    "    # Calcular flota total por transportador por día\n",
    "    total_daily_fleet = schedule_df.groupby(['DIA', 'TRANSPORTADOR'])['QTD_VEICULOS'].sum().reset_index()\n",
    "    total_daily_fleet.rename(columns={'QTD_VEICULOS': 'TOTAL_VEHICULOS_DIA'}, inplace=True)\n",
    "\n",
    "    # Unir con la asignación por UP y la info de grúa\n",
    "    merged = pd.merge(schedule_df, total_daily_fleet, on=['DIA', 'TRANSPORTADOR'])\n",
    "    merged = pd.merge(merged, df_grua[['TRANSPORTADOR', 'PORCENTAGEM_VEICULOS_MIN']], on='TRANSPORTADOR')\n",
    "\n",
    "    # Calcular porcentaje real\n",
    "    merged['PORCENTAJE_REAL'] = merged['QTD_VEICULOS'] / merged['TOTAL_VEHICULOS_DIA']\n",
    "\n",
    "    # Añadir tolerancia pequeña\n",
    "    tolerance = 1e-6\n",
    "    violations = merged[merged['PORCENTAJE_REAL'] < merged['PORCENTAGEM_VEICULOS_MIN'] - tolerance]\n",
    "\n",
    "    if not violations.empty:\n",
    "        print(\"Incumplimiento - Vehículos Mínimos por UP:\")\n",
    "        # Mostrar solo columnas relevantes para la violación\n",
    "        print(violations[['DIA', 'TRANSPORTADOR', 'UP', 'QTD_VEICULOS', 'TOTAL_VEHICULOS_DIA', 'PORCENTAGEM_VEICULOS_MIN', 'PORCENTAJE_REAL']])\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# --- Funciones de Validación de Completitud (Más Complejas) ---\n",
    "# Estas requieren analizar el historial a través de los días\n",
    "\n",
    "def check_continuity(days_list):\n",
    "    \"\"\"Función auxiliar para verificar continuidad y número de bloques.\"\"\"\n",
    "    if not days_list:\n",
    "        return 0, True # 0 bloques, continuo\n",
    "    \n",
    "    sorted_days = sorted(list(set(days_list)))\n",
    "    if not sorted_days:\n",
    "      return 0, True\n",
    "\n",
    "    blocks = 0\n",
    "    is_continuous = True\n",
    "    if sorted_days:\n",
    "        blocks = 1\n",
    "        for i in range(len(sorted_days) - 1):\n",
    "            if sorted_days[i+1] != sorted_days[i] + 1:\n",
    "                blocks += 1\n",
    "                is_continuous = False # Hay un salto\n",
    "    return blocks, is_continuous\n",
    "\n",
    "def validate_completion_rules(schedule_df, df_bd_up):\n",
    "    \"\"\"Valida las reglas de transporte completo/fraccionado para UPs y Fazendas.\"\"\"\n",
    "    all_valid = True\n",
    "    total_volume_transported = schedule_df.groupby('UP')['VOLUME'].sum()\n",
    "    \n",
    "    # 1. Validación por UP\n",
    "    for up_id, group in schedule_df.groupby('UP'):\n",
    "        up_info = df_bd_up[df_bd_up['UP'] == up_id].iloc[0]\n",
    "        total_volume_up = up_info['VOLUME']\n",
    "        volume_transported_up = total_volume_transported.get(up_id, 0)\n",
    "        days_worked = group['DIA'].tolist()\n",
    "        num_blocks, is_continuous = check_continuity(days_worked)\n",
    "\n",
    "        is_small_up = total_volume_up < 7000\n",
    "\n",
    "        # Regla UP Pequeña (<7000 m³)\n",
    "        if is_small_up:\n",
    "            # Debe ser transportada completamente si se empezó\n",
    "            if 0 < volume_transported_up < total_volume_up:\n",
    "                 print(f\"Incumplimiento UP < 7000: UP {up_id} iniciada pero no completada. Transportado: {volume_transported_up:.2f}, Total: {total_volume_up:.2f}\")\n",
    "                 all_valid = False\n",
    "            # Debe tener solo 1 entrada (ser continua)\n",
    "            if num_blocks > 1:\n",
    "                 print(f\"Incumplimiento UP < 7000: UP {up_id} tiene {num_blocks} entradas (debe ser 1). Días: {sorted(list(set(days_worked)))}\")\n",
    "                 all_valid = False\n",
    "\n",
    "        # Regla UP Grande (>=7000 m³)\n",
    "        else:\n",
    "            # Puede tener hasta 2 entradas\n",
    "            if num_blocks > 2:\n",
    "                 print(f\"Incumplimiento UP >= 7000: UP {up_id} tiene {num_blocks} entradas (máximo 2). Días: {sorted(list(set(days_worked)))}\")\n",
    "                 all_valid = False\n",
    "\n",
    "    # # # 2. Validación por Fazenda (Simplificada: verifica si fue completada si se inició)\n",
    "    # # # Una validación completa requeriría verificar si el transportador cambió *antes* de completar.\n",
    "    # # # Esta versión solo chequea si el volumen total fue transportado al final del horizonte.\n",
    "    # fazenda_volume_transported = schedule_df.groupby('FAZENDA')['VOLUME'].sum()\n",
    "    # # Calcular volumen total por Fazenda desde BD_UP\n",
    "    # fazenda_total_volume = df_bd_up.groupby('FAZENDA')['VOLUME'].sum()\n",
    "\n",
    "    # for fazenda, transported in fazenda_volume_transported.items():\n",
    "    #     total = fazenda_total_volume.get(fazenda, 0)\n",
    "    #     # Si se transportó algo pero no todo, es una violación potencial (simplificada)\n",
    "    #     # La regla estricta es más compleja de verificar sin seguir estados diarios.\n",
    "    #     if 0 < transported < total:\n",
    "    #         # Esto es una indicación, no una prueba definitiva de violación de la regla *durante* la ejecución\n",
    "    #         print(f\"Advertencia - Completitud Fazenda: Fazenda {fazenda} iniciada pero no completada al final del horizonte. Transportado: {transported:.2f}, Total: {total:.2f}\")\n",
    "    #         all_valid = False # Podrías marcarlo como inválido aquí si quieres ser estricto con el resultado final\n",
    "\n",
    "    return all_valid\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37cf032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Función Principal de Validación ---\n",
    "def validate_essential_constraints(schedule_df, df_fabrica, df_frota, df_grua, df_bd_up,flag):\n",
    "    # \"\"\"Ejecuta todas las validaciones.\"\"\"\n",
    "    # print(\"--- Iniciando Validación de Restricciones ---\")\n",
    "    is_feasible = True\n",
    "\n",
    "    # Limpiar columna auxiliar de RSP si existe de ejecuciones anteriores\n",
    "    if 'RSP_WEIGHTED_SUM' in schedule_df.columns:\n",
    "        schedule_df.drop(columns=['RSP_WEIGHTED_SUM'], inplace=True, errors='ignore')\n",
    "\n",
    "    if not validate_daily_demand(schedule_df, df_fabrica,flag): is_feasible = False\n",
    "    if not validate_daily_rsp(schedule_df, df_fabrica,flag): is_feasible = False\n",
    "    if not validate_transporter_fleet_size(schedule_df, df_frota): is_feasible = False\n",
    "    if not validate_crane_capacity(schedule_df, df_grua): is_feasible = False\n",
    "    # if not validate_fazenda_exclusivity(schedule_df): is_feasible = False\n",
    "    \n",
    "    return is_feasible\n",
    "\n",
    "# --- Función Principal de Validación ---\n",
    "def validate_all_constraints(schedule_df, df_fabrica, df_frota, df_grua, df_bd_up,flag):\n",
    "    \"\"\"Ejecuta todas las validaciones.\"\"\"\n",
    "    # print(\"--- Iniciando Validación de Restricciones ---\")\n",
    "    is_feasible = True\n",
    "\n",
    "    # Limpiar columna auxiliar de RSP si existe de ejecuciones anteriores\n",
    "    if 'RSP_WEIGHTED_SUM' in schedule_df.columns:\n",
    "        schedule_df.drop(columns=['RSP_WEIGHTED_SUM'], inplace=True, errors='ignore')\n",
    "\n",
    "    if not validate_daily_demand(schedule_df, df_fabrica,flag): is_feasible = False\n",
    "    if not validate_daily_rsp(schedule_df, df_fabrica,flag): is_feasible = False\n",
    "    if not validate_transporter_fleet_size(schedule_df, df_frota): is_feasible = False\n",
    "    if not validate_crane_capacity(schedule_df, df_grua): is_feasible = False\n",
    "    if not validate_fazenda_exclusivity(schedule_df): is_feasible = False\n",
    "    # OJO: La validación de min_vehicles_per_up puede fallar si hay días/transportadores sin asignaciones en schedule_df\n",
    "    # Se necesita asegurar que schedule_df contenga todas las asignaciones relevantes.\n",
    "    # if not validate_min_vehicles_per_up(schedule_df, df_grua): is_feasible = False # Puede necesitar ajustes\n",
    "    if not validate_completion_rules(schedule_df, df_bd_up): is_feasible = False\n",
    "\n",
    "    print(\"--- Validación Terminada ---\")\n",
    "    if is_feasible:\n",
    "        print(\">>> La solución CUMPLE con todas las restricciones verificadas.\")\n",
    "    else:\n",
    "        print(\">>> La solución NO CUMPLE con una o más restricciones.\")\n",
    "\n",
    "    return is_feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "158bf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Funciones Auxiliares ---\n",
    "def calculate_daily_transport_volume(vehicles, caixa_carga, tempo_ciclo):\n",
    "    \"\"\"Calcula el volumen máximo que pueden transportar los vehículos en un día.\"\"\"\n",
    "    if vehicles <= 0 or caixa_carga <= 0 or tempo_ciclo <= 0:\n",
    "        return 0\n",
    "    return vehicles * caixa_carga * tempo_ciclo\n",
    "\n",
    "def check_continuity(days_list):\n",
    "    \"\"\"Función auxiliar para verificar continuidad y número de bloques.\"\"\"\n",
    "    if not isinstance(days_list, list) or not days_list:\n",
    "         return 0, True\n",
    "    \n",
    "    sorted_days = sorted(list(set(filter(None, days_list)))) # Filtra None o NaNs\n",
    "    if not sorted_days:\n",
    "      return 0, True\n",
    "\n",
    "    blocks = 0\n",
    "    if sorted_days:\n",
    "        blocks = 1\n",
    "        for i in range(len(sorted_days) - 1):\n",
    "            if sorted_days[i+1] != sorted_days[i] + 1:\n",
    "                blocks += 1\n",
    "    is_continuous = (blocks <= 1) # Consideramos continuo si hay 0 o 1 bloque\n",
    "    return blocks, is_continuous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aaef612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Heurística Constructiva ---\n",
    "\n",
    "def constructive_heuristic(df_horizonte, df_bd_up, df_frota, df_grua, df_fabrica, df_rota,flag):\n",
    "    \"\"\"\n",
    "    Intenta construir una solución factible día por día.\n",
    "    \"\"\"\n",
    "    schedule = [] # Lista para guardar las filas de la solución\n",
    "\n",
    "    # --- Inicializar Estado ---\n",
    "    up_status = df_bd_up.set_index('UP').copy() # Usar UP como índice para fácil acceso\n",
    "    up_status['VOLUME_RESTANTE'] = up_status['VOLUME']\n",
    "    # Inicializar DIAS_TRABAJADOS como una lista vacía para cada fila\n",
    "    up_status['DIAS_TRABAJADOS'] = [[] for _ in range(len(up_status))]\n",
    "    up_status['BLOQUES_TRABAJO'] = 0\n",
    "    up_status['ESTADO'] = 'PENDIENTE' # PENDIENTE, ACTIVA, COMPLETADA, PAUSADA (>7000m3 only)\n",
    "\n",
    "    # Estado del transportador por día (se resetea/actualiza cada día)\n",
    "    transporter_daily_status = {t: {'fazenda_actual': None, 'ups_activas_hoy': [], 'vehiculos_usados_hoy': 0}\n",
    "                                for t in df_frota['TRANSPORTADOR']}\n",
    "\n",
    "    # Guardar la última Fazenda trabajada por un transportador para continuidad\n",
    "    transporter_last_fazenda = {t: None for t in df_frota['TRANSPORTADOR']}\n",
    "    transportadores=list(df_frota['TRANSPORTADOR'].unique())\n",
    "    random.shuffle(transportadores)\n",
    "    # print(up_status)\n",
    "    # print(\"hi i'm here\")\n",
    "    up_status=up_status.sample(frac=1)\n",
    "    # print(up_status)\n",
    "    # print(\"--- Iniciando Heurística Constructiva ---\")\n",
    "\n",
    "    # --- Bucle Principal por Día ---\n",
    "    for _, dia_info in df_horizonte.iterrows():\n",
    "        dia = dia_info['DIA']\n",
    "        mes = dia_info['MES']\n",
    "        # print(f\"\\n--- Construyendo Día {dia} ---\")\n",
    "\n",
    "        # Resetear estado diario (mantener fazenda si es necesario?)\n",
    "        for t in transporter_daily_status:\n",
    "            transporter_daily_status[t]['ups_activas_hoy'] = []\n",
    "            transporter_daily_status[t]['vehiculos_usados_hoy'] = 0\n",
    "            # ¿Debería mantenerse la fazenda_actual si no se completó? Sí.\n",
    "            # transporter_daily_status[t]['fazenda_actual'] = None # Resetear o mantener?\n",
    "\n",
    "        # Obtener demandas y límites del día\n",
    "\n",
    "        volumen_acumulado_dia = 0\n",
    "\n",
    "        # --- Priorización de UPs ---\n",
    "        # 1. UPs Activas o Pausadas (que deben continuarse)\n",
    "        # 2. UPs Pendientes\n",
    "        # Podría añadirse más lógica (ej. por RSP para cumplir objetivo diario)\n",
    "        ups_activas_pausadas = up_status[up_status['ESTADO'].isin(['ACTIVA', 'PAUSADA'])].index.tolist()\n",
    "        ups_pendientes = up_status[up_status['ESTADO'] == 'PENDIENTE'].index.tolist()\n",
    "        # Simple Prio: Activas/Pausadas primero, luego Pendientes (podría ordenarse mejor)\n",
    "        ups_priorizadas = ups_activas_pausadas + ups_pendientes\n",
    "\n",
    "        # --- Bucle por Transportador ---\n",
    "        # Podríamos ordenar transportadores (ej. por capacidad) pero lo hacemos simple\n",
    "        \n",
    "        for transportador in transportadores:\n",
    "            \n",
    "            transportador_info = df_frota[df_frota['TRANSPORTADOR'] == transportador].iloc[0]\n",
    "            grua_info = df_grua[df_grua['TRANSPORTADOR'] == transportador].iloc[0]\n",
    "            frota_min_transp = transportador_info['FROTA_MIN']\n",
    "            frota_max_transp = transportador_info['FROTA_MAX']\n",
    "            qtd_gruas_transp = grua_info['QTD_GRUAS']\n",
    "            \n",
    "            # --- Determinar Fazenda Objetivo ---\n",
    "            fazenda_objetivo = None\n",
    "            # Si el transportador estaba activo en una Fazenda ayer y no la completó, DEBE continuarla.\n",
    "            fazenda_previa = transporter_last_fazenda[transportador]\n",
    "            if fazenda_previa:\n",
    "                 ups_en_fazenda_previa = up_status[up_status['FAZENDA'] == fazenda_previa]\n",
    "                 # Si *alguna* UP en esa fazenda está ACTIVA o PAUSADA, debe continuarla.\n",
    "                 if any(ups_en_fazenda_previa['ESTADO'].isin(['ACTIVA', 'PAUSADA'])):\n",
    "                     fazenda_objetivo = fazenda_previa\n",
    "                    #  print(f\"  {transportador} debe continuar Fazenda: {fazenda_objetivo}\")\n",
    "            \n",
    "            # Si no hay obligación de continuar, buscar una nueva Fazenda (o continuar una opcionalmente)\n",
    "            if not fazenda_objetivo:\n",
    "                 # Estrategia simple: Elegir la primera fazenda con UPs pendientes/activas que pueda atender\n",
    "                 possible_fazendas = up_status[up_status.index.isin(ups_priorizadas)]['FAZENDA'].unique()\n",
    "                 if (len(possible_fazendas)>0):\n",
    "                     random.shuffle(possible_fazendas)\n",
    "                #  print(possible_fazendas)\n",
    "                 for f in possible_fazendas:\n",
    "                     # Verificar si hay ruta para *alguna* UP en esa fazenda\n",
    "                     ups_in_f = up_status[(up_status['FAZENDA'] == f) & (up_status.index.isin(ups_priorizadas))].index\n",
    "                     if any(not df_rota[(df_rota['ORIGEM'] == up) & (df_rota['TRANSPORTADOR'] == transportador)].empty for up in ups_in_f):\n",
    "                          fazenda_objetivo = f\n",
    "                        #   print(f\"  {transportador} elige nueva Fazenda: {fazenda_objetivo}\")\n",
    "                          break # Elegir la primera encontrada\n",
    "\n",
    "            if not fazenda_objetivo:\n",
    "                print(f\"  {transportador} no encontró Fazenda objetivo hoy.\")\n",
    "                transporter_last_fazenda[transportador] = None # No trabajó\n",
    "                continue # Siguiente transportador\n",
    "                \n",
    "            transporter_daily_status[transportador]['fazenda_actual'] = fazenda_objetivo\n",
    "            transporter_last_fazenda[transportador] = fazenda_objetivo # Actualizar la última trabajada\n",
    "\n",
    "            # --- Seleccionar UPs dentro de la Fazenda Objetivo ---\n",
    "            ups_seleccionadas_hoy = []\n",
    "            # Filtrar UPs priorizadas que estén en la fazenda objetivo\n",
    "            ups_candidatas_fazenda = [up for up in ups_priorizadas if up_status.loc[up, 'FAZENDA'] == fazenda_objetivo]\n",
    "            # print(\"FLAGGGGGGG\", ups_candidatas_fazenda)\n",
    "            for up_id in ups_candidatas_fazenda:\n",
    "                if len(ups_seleccionadas_hoy) >= qtd_gruas_transp:\n",
    "                    break # Límite de grúas alcanzado\n",
    "\n",
    "                # Verificar si hay ruta\n",
    "                rota_info = df_rota[(df_rota['ORIGEM'] == up_id) & (df_rota['TRANSPORTADOR'] == transportador)]\n",
    "                if rota_info.empty:\n",
    "                    continue\n",
    "\n",
    "                # Verificar Reglas de Completitud/Fragmentación ANTES de añadir\n",
    "                up_data = up_status.loc[up_id]\n",
    "                vol_total = up_data['VOLUME']\n",
    "                vol_restante = up_data['VOLUME_RESTANTE']\n",
    "                estado_actual = up_data['ESTADO']\n",
    "                bloques_actuales = up_data['BLOQUES_TRABAJO']\n",
    "\n",
    "                if vol_restante <= 0: continue # Ya completada\n",
    "\n",
    "                puede_empezar_o_continuar = False\n",
    "                if estado_actual == 'PENDIENTE':\n",
    "                    # Si es pequeña (<7000), solo puede empezar si se puede terminar hoy (simplificación: difícil saber a priori)\n",
    "                    # Omitimos esa check compleja por ahora y permitimos empezar.\n",
    "                    # Si es grande (>=7000), puede empezar si bloques < 2\n",
    "                    if vol_total < 7000:\n",
    "                         puede_empezar_o_continuar = True # Asumimos que puede empezar\n",
    "                    elif bloques_actuales < 2:\n",
    "                         puede_empezar_o_continuar = True\n",
    "                elif estado_actual == 'ACTIVA':\n",
    "                     puede_empezar_o_continuar = True # Puede continuar\n",
    "                elif estado_actual == 'PAUSADA':\n",
    "                     # Solo puede continuar si bloques < 2\n",
    "                     if bloques_actuales < 2:\n",
    "                          puede_empezar_o_continuar = True\n",
    "\n",
    "                if puede_empezar_o_continuar:\n",
    "                    ups_seleccionadas_hoy.append(up_id)\n",
    "\n",
    "            if not ups_seleccionadas_hoy:\n",
    "                print(f\"  {transportador} no encontró UPs viables en {fazenda_objetivo} hoy.\")\n",
    "                continue\n",
    "\n",
    "            # print(f\"  {transportador} en {fazenda_objetivo} -> UPs: {ups_seleccionadas_hoy}\")\n",
    "\n",
    "            # --- Asignar Vehículos y Calcular Volumen ---\n",
    "            num_ups_asignadas = len(ups_seleccionadas_hoy)\n",
    "            vehiculos_total_asignar = 0\n",
    "\n",
    "            # Intentar asignar al menos el mínimo de flota, distribuido\n",
    "            if num_ups_asignadas > 0:\n",
    "                 vehiculos_total_asignar = frota_max_transp#random.randint(frota_min_transp,frota_max_transp)\n",
    "\n",
    "            distr=random.random()\n",
    "            veh_up=[0 for _ in range (num_ups_asignadas)]\n",
    "            ass_veh=vehiculos_total_asignar\n",
    "            perc=grua_info[\"PORCENTAGEM_VEICULOS_MIN\"]\n",
    "\n",
    "            for i in range (num_ups_asignadas):\n",
    "                if  (num_ups_asignadas==1):\n",
    "                    veh_up[i]=int(vehiculos_total_asignar)\n",
    "                    ass_veh-=veh_up[i]   \n",
    "                elif distr< perc and i==0 and ass_veh>0:\n",
    "                    veh_up[i]=math.ceil(perc*vehiculos_total_asignar)\n",
    "                    ass_veh-=veh_up[i]\n",
    "                elif distr > perc and distr<(1-perc) and i==0 and ass_veh>0:\n",
    "                    veh_up[i]=math.ceil(distr*vehiculos_total_asignar)\n",
    "                    ass_veh-=veh_up[i]   \n",
    "                elif (distr > perc and i==0) and ass_veh>0:\n",
    "                    veh_up[i]=int(vehiculos_total_asignar)\n",
    "                    ass_veh-=veh_up[i]   \n",
    "                   \n",
    "                else:\n",
    "                    veh_up[i]=min(math.ceil((1-perc)*vehiculos_total_asignar),ass_veh)\n",
    "                    ass_veh-=max(veh_up[i],0)\n",
    "\n",
    "\n",
    "            # Distribución simple (podría ser proporcional al volumen restante, etc.)\n",
    "            vehiculos_por_up = {}\n",
    "            if num_ups_asignadas > 0:\n",
    "                \n",
    "                for idx,up_id in enumerate(ups_seleccionadas_hoy):\n",
    "                     vehi_up = veh_up[idx]\n",
    "\n",
    "                     \n",
    "                     # Verificar si con estos vehículos se puede transportar *algo*\n",
    "                     rota_info = df_rota[(df_rota['ORIGEM'] == up_id) & (df_rota['TRANSPORTADOR'] == transportador)].iloc[0]\n",
    "                     caixa = rota_info['CAIXA_CARGA']\n",
    "                     ciclo = rota_info['TEMPO_CICLO'] # TODO: Ajustar por ciclo lento? (PDF no especifica cómo)\n",
    "                     vol_potencial_up = calculate_daily_transport_volume(vehi_up, caixa, ciclo)\n",
    "                     \n",
    "                     if vol_potencial_up > 0:\n",
    "                         vehiculos_por_up[up_id] = vehi_up\n",
    "\n",
    "                         \n",
    "                # Recalcular UPs activas y vehículos totales usados hoy\n",
    "                ups_seleccionadas_hoy = list(vehiculos_por_up.keys())\n",
    "                vehiculos_usados_transp_hoy = sum(vehiculos_por_up.values())\n",
    "                \n",
    "                # Validar flota total usada hoy\n",
    "                if not (frota_min_transp <= vehiculos_usados_transp_hoy <= frota_max_transp):\n",
    "                     print(f\"Error interno: Flota calculada ({vehiculos_usados_transp_hoy}) fuera de rango [{frota_min_transp}, {frota_max_transp}] para {transportador}\")\n",
    "                     pass\n",
    "\n",
    "                transporter_daily_status[transportador]['vehiculos_usados_hoy'] = vehiculos_usados_transp_hoy\n",
    "                transporter_daily_status[transportador]['ups_activas_hoy'] = ups_seleccionadas_hoy\n",
    "\n",
    "            # --- Calcular Volumen Transportado y Actualizar Estado ---\n",
    "            for up_id in ups_seleccionadas_hoy:\n",
    "                vehi_up = vehiculos_por_up[up_id]\n",
    "                up_data = up_status.loc[up_id] # Obtener datos actuales\n",
    "                rota_info = df_rota[(df_rota['ORIGEM'] == up_id) & (df_rota['TRANSPORTADOR'] == transportador)].iloc[0]\n",
    "                caixa = rota_info['CAIXA_CARGA']\n",
    "                ciclo = rota_info['TEMPO_CICLO'] # TODO: Ajustar ciclo lento\n",
    "                \n",
    "                vol_max_transportable_hoy = calculate_daily_transport_volume(vehi_up, caixa, ciclo)\n",
    "                vol_real_transportado = min(vol_max_transportable_hoy, up_data['VOLUME_RESTANTE'])\n",
    "\n",
    "                if vol_real_transportado > 0:\n",
    "                    # Actualizar volumen restante\n",
    "                    up_status.loc[up_id, 'VOLUME_RESTANTE'] -= vol_real_transportado\n",
    "\n",
    "                    # --- Inicialización Segura de dias_previos ---\n",
    "                    try:\n",
    "                        # Intenta obtener la lista actual\n",
    "                        retrieved_days = up_status.loc[up_id, 'DIAS_TRABAJADOS']\n",
    "                        # Verifica si es una lista válida, si no, inicializa como vacía\n",
    "                        if isinstance(retrieved_days, list):\n",
    "                            dias_previos = retrieved_days.copy() # Usar .copy() por seguridad\n",
    "                        else:\n",
    "                            dias_previos = []\n",
    "                    except KeyError:\n",
    "                        # Error si up_id no existe (no debería pasar aquí, pero por seguridad)\n",
    "                        print(f\"Error Crítico: UP {up_id} no encontrado en up_status index.\")\n",
    "                        dias_previos = []\n",
    "                    except Exception as e:\n",
    "                            # Cualquier otro error inesperado al leer\n",
    "                            print(f\"Error inesperado al leer DIAS_TRABAJADOS para {up_id}: {e}\")\n",
    "                            dias_previos = []\n",
    "                    # --- Fin Inicialización Segura ---\n",
    "\n",
    "                    # Ahora estamos seguros de que 'dias_previos' es una lista\n",
    "\n",
    "                    nuevo_estado = 'ACTIVA'\n",
    "\n",
    "                    # Verificar si es un nuevo bloque de trabajo\n",
    "                    # Un bloque nuevo empieza si la lista estaba vacía O si el día actual no es consecutivo al último registrado\n",
    "                    is_new_block = False\n",
    "                    if not dias_previos: # Es el primer día que se trabaja esta UP\n",
    "                        is_new_block = True\n",
    "                    elif dia != dias_previos[-1] + 1: # Hubo una interrupción (día no consecutivo)\n",
    "                        is_new_block = True\n",
    "\n",
    "                    # Incrementar contador de bloques SOLO si es un nuevo bloque Y NO es el primer día en absoluto\n",
    "                    if is_new_block and dias_previos:\n",
    "                        # Asegúrate de que BLOQUES_TRABAJO exista y sea numérico\n",
    "                            if pd.isna(up_status.loc[up_id, 'BLOQUES_TRABAJO']):\n",
    "                                up_status.loc[up_id, 'BLOQUES_TRABAJO'] = 0\n",
    "                            up_status.loc[up_id, 'BLOQUES_TRABAJO'] += 1\n",
    "\n",
    "                    # Añadir día actual a la lista si no está ya (por si acaso)\n",
    "                    if dia not in dias_previos:\n",
    "                        dias_previos.append(dia)\n",
    "\n",
    "                    # Reasignar la lista actualizada usando .at para seguridad\n",
    "                    up_status.at[up_id, 'DIAS_TRABAJADOS'] = dias_previos\n",
    "\n",
    "                    # Actualizar estado final de la UP para hoy\n",
    "                    if up_status.loc[up_id, 'VOLUME_RESTANTE'] <= 1e-6: # Usar tolerancia para flotantes\n",
    "                        nuevo_estado = 'COMPLETADA'\n",
    "                    # (Podrías añadir lógica para PAUSADA si es UP grande y se interrumpe, pero la dejaremos ACTIVA por ahora)\n",
    "                    up_status.loc[up_id, 'ESTADO'] = nuevo_estado\n",
    "\n",
    "                    # Añadir la entrada al schedule (DataFrame final)\n",
    "                    schedule.append({\n",
    "                        'UP': up_id,\n",
    "                        'FAZENDA': up_data['FAZENDA'], # Necesitas obtener up_data antes en el loop\n",
    "                        'TRANSPORTADOR': transportador,\n",
    "                        'DIA': dia,\n",
    "                        'MES': mes,\n",
    "                        'DB': up_data['DB'],      # Necesitas obtener up_data antes en el loop\n",
    "                        'RSP': up_data['RSP'],     # Necesitas obtener up_data antes en el loop\n",
    "                        'QTD_VEICULOS': vehi_up,\n",
    "                        'VOLUME': vol_real_transportado\n",
    "                    })\n",
    "                    volumen_acumulado_dia += vol_real_transportado\n",
    "                    # print(f\"    -> {transportador} transporta {vol_real_transportado:.2f} m³ desde {up_id} ({nuevo_estado})\")\n",
    "\n",
    "                    up_status.loc[up_id, 'ESTADO'] = nuevo_estado\n",
    "\n",
    "\n",
    "    # --- Fin del Horizonte ---\n",
    "    final_schedule_df = pd.DataFrame(schedule)\n",
    "\n",
    "    # print(\"--- Heurística Constructiva Terminada ---\")\n",
    "    return final_schedule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb015573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_day(schedule_df_day, df_fabrica_day, df_frota, df_grua):\n",
    "    \"\"\"\n",
    "    Validates essential constraints for a single day's schedule.\n",
    "    Returns True if feasible, False otherwise.\n",
    "    \"\"\"\n",
    "    if schedule_df_day is None or schedule_df_day.empty:\n",
    "        if df_fabrica_day is None or df_fabrica_day.empty:\n",
    "            print(\"  ERROR: Factory data for the day is missing.\")\n",
    "            return False\n",
    "        if 'DEMANDA_MIN' not in df_fabrica_day.columns:\n",
    "            print(\"  ERROR: 'DEMANDA_MIN' column missing in factory data.\")\n",
    "            return False\n",
    "        # An empty schedule is feasible only if minimum demand is 0\n",
    "        return df_fabrica_day['DEMANDA_MIN'].iloc[0] <= 1e-6 # Use tolerance\n",
    "\n",
    "    if 'DIA' not in schedule_df_day.columns or schedule_df_day.empty:\n",
    "         print(\"  ERROR: Schedule DataFrame is empty or missing 'DIA' column.\")\n",
    "         return False\n",
    "\n",
    "    # Ensure day value is valid before using it\n",
    "    try:\n",
    "        day = int(schedule_df_day['DIA'].iloc[0])\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"  ERROR: Invalid or missing day value in schedule_df_day.\")\n",
    "        return False\n",
    "\n",
    "    if not isinstance(df_fabrica_day, pd.DataFrame):\n",
    "        print(f\"  ERROR: df_fabrica_day is not a DataFrame for day {day}\")\n",
    "        return False\n",
    "\n",
    "    fabrica_constraints = df_fabrica_day[df_fabrica_day['DIA'] == day]\n",
    "    if fabrica_constraints.empty:\n",
    "         print(f\"  ERROR: No factory constraints found for day {day}\")\n",
    "         return False\n",
    "\n",
    "    flag = 0 # Internal flag for sub-validations\n",
    "    is_feasible = True\n",
    "    try:\n",
    "        # Ensure validation functions are defined and callable\n",
    "        if 'validate_daily_demand' not in globals() or not callable(globals()['validate_daily_demand']) or \\\n",
    "           'validate_daily_rsp' not in globals() or not callable(globals()['validate_daily_rsp']) or \\\n",
    "           'validate_transporter_fleet_size' not in globals() or not callable(globals()['validate_transporter_fleet_size']) or \\\n",
    "           'validate_crane_capacity' not in globals() or not callable(globals()['validate_crane_capacity']) or \\\n",
    "           'validate_fazenda_exclusivity' not in globals() or not callable(globals()['validate_fazenda_exclusivity']):\n",
    "            print(\"  ERROR: One or more required validation functions are not defined.\")\n",
    "            return False\n",
    "\n",
    "        if not validate_daily_demand(schedule_df_day, fabrica_constraints, flag): is_feasible = False\n",
    "        if not validate_daily_rsp(schedule_df_day, fabrica_constraints, flag): is_feasible = False\n",
    "        if not validate_transporter_fleet_size(schedule_df_day, df_frota): is_feasible = False\n",
    "        if not validate_crane_capacity(schedule_df_day, df_grua): is_feasible = False\n",
    "        if not validate_fazenda_exclusivity(schedule_df_day): is_feasible = False\n",
    "        # Optional: Validate min vehicles per UP\n",
    "        # if 'validate_min_vehicles_per_up' in globals() and callable(globals()['validate_min_vehicles_per_up']):\n",
    "        #     try:\n",
    "        #         if not validate_min_vehicles_per_up(schedule_df_day, df_grua): is_feasible = False\n",
    "        #     except Exception as e_min_veh:\n",
    "        #         print(f\"  WARN: validate_min_vehicles_per_up failed for day {day}: {e_min_veh}\")\n",
    "        # else:\n",
    "        #     print(\"  WARN: validate_min_vehicles_per_up function not defined, skipping check.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: Exception during single day validation for day {day}: {e}\")\n",
    "        return False\n",
    "\n",
    "    return is_feasible\n",
    "\n",
    "def find_feasible_daily_pattern(target_day, current_up_status, df_horizonte, df_frota, df_grua, df_fabrica, df_rota, max_attempts=100):\n",
    "    \"\"\"\n",
    "    Tries to find a feasible schedule pattern for a single target_day.\n",
    "    Returns the first feasible pattern found, or the last attempt if none are feasible.\n",
    "    \"\"\"\n",
    "    # print(f\"  Attempting to find feasible pattern for Day {target_day}...\") # Reduce verbosity\n",
    "    horizon_day_info = df_horizonte[df_horizonte['DIA'] == target_day]\n",
    "    if horizon_day_info.empty:\n",
    "        print(f\"  ERROR: No horizon data found for Day {target_day}. Cannot proceed.\")\n",
    "        return None, False # Return None and feasibility status\n",
    "\n",
    "    mes_val = horizon_day_info['MES'].iloc[0] if 'MES' in horizon_day_info.columns else None\n",
    "    ano_val = horizon_day_info['ANO'].iloc[0] if 'ANO' in horizon_day_info.columns else None\n",
    "    df_horizonte_day = pd.DataFrame([{'DIA': target_day, 'MES': mes_val, 'ANO': ano_val}])\n",
    "\n",
    "    df_fabrica_day = df_fabrica[df_fabrica['DIA'] == target_day].copy()\n",
    "    if df_fabrica_day.empty:\n",
    "        print(f\"  ERROR: No factory data found for Day {target_day}. Cannot proceed.\")\n",
    "        return None, False\n",
    "\n",
    "    last_attempt_schedule = None # Store the last generated schedule\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        temp_up_status_indexed = current_up_status.copy()\n",
    "        temp_up_status_columnar = temp_up_status_indexed.reset_index()\n",
    "        daily_schedule_attempt = None # Initialize before try block\n",
    "\n",
    "        try:\n",
    "            # Ensure constructive_heuristic function is defined and callable\n",
    "            if 'constructive_heuristic' not in globals() or not callable(globals()['constructive_heuristic']):\n",
    "                 print(\"  ERROR: `constructive_heuristic` function not defined.\")\n",
    "                 return None, False # Cannot proceed\n",
    "\n",
    "            daily_schedule_attempt = constructive_heuristic(\n",
    "                df_horizonte_day, temp_up_status_columnar, df_frota, df_grua,\n",
    "                df_fabrica_day, df_rota, flag=0\n",
    "            )\n",
    "            last_attempt_schedule = daily_schedule_attempt # Store the latest attempt\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: Exception in constructive_heuristic attempt {attempt+1}: {e}\")\n",
    "            # Continue to next attempt, maybe it works\n",
    "            continue\n",
    "\n",
    "        if daily_schedule_attempt is not None and not daily_schedule_attempt.empty:\n",
    "             if 'DIA' in daily_schedule_attempt.columns:\n",
    "                 daily_schedule_attempt = daily_schedule_attempt[daily_schedule_attempt['DIA'] == target_day].copy()\n",
    "             else:\n",
    "                 print(f\"  WARN: Heuristic output missing 'DIA' column (Day {target_day}, Att {attempt+1}).\")\n",
    "                 daily_schedule_attempt = pd.DataFrame() # Treat as empty\n",
    "\n",
    "        # Validate this single day's schedule\n",
    "        if validate_single_day(daily_schedule_attempt, df_fabrica_day, df_frota, df_grua):\n",
    "            # Return the first feasible pattern found\n",
    "            if not daily_schedule_attempt.empty:\n",
    "                 # print(f\"    Found feasible pattern Day {target_day} Att {attempt + 1}.\") # Reduce verbosity\n",
    "                 return daily_schedule_attempt, True # Return pattern and True for feasible\n",
    "            else:\n",
    "                 # Handle feasible empty schedule case\n",
    "                 if 'DEMANDA_MIN' in df_fabrica_day.columns and df_fabrica_day['DEMANDA_MIN'].iloc[0] <= 1e-6:\n",
    "                      # print(f\"    Found feasible EMPTY pattern Day {target_day} Att {attempt + 1}.\") # Reduce verbosity\n",
    "                      return daily_schedule_attempt, True # Return empty pattern and True\n",
    "                 # else: continue loop if empty schedule validated but demand > 0\n",
    "\n",
    "    # If loop finishes without finding a feasible pattern\n",
    "    print(f\"  WARN: Failed to find feasible pattern for Day {target_day} after {max_attempts} attempts. Using last attempt.\")\n",
    "    # Return the last generated schedule (even if infeasible) and False\n",
    "    return last_attempt_schedule, False\n",
    "\n",
    "def calculate_extension_days(daily_pattern, current_up_status, horizon_end_day, current_day):\n",
    "    \"\"\"\n",
    "    Calculates how many days the daily_pattern can be repeated based on volume.\n",
    "    Returns 0 if the pattern cannot be applied even once (e.g., required UP is empty).\n",
    "    \"\"\"\n",
    "    if daily_pattern is None or daily_pattern.empty: return 0\n",
    "\n",
    "    max_k = float('inf')\n",
    "    pattern_requires_volume = False\n",
    "\n",
    "    if 'UP' not in daily_pattern.columns or 'VOLUME' not in daily_pattern.columns:\n",
    "        print(\"  ERROR: Daily pattern missing 'UP' or 'VOLUME' column.\")\n",
    "        return 0\n",
    "\n",
    "    volume_per_up_in_pattern = daily_pattern.groupby('UP')['VOLUME'].sum()\n",
    "\n",
    "    # Check if pattern transports any volume at all\n",
    "    if volume_per_up_in_pattern.empty or volume_per_up_in_pattern.max() <= 1e-6:\n",
    "         days_left_in_horizon = horizon_end_day - current_day + 1\n",
    "         return min(1, days_left_in_horizon) # Extend empty/zero-volume pattern by 1 day\n",
    "\n",
    "    for up_id, daily_vol_transported in volume_per_up_in_pattern.items():\n",
    "        if daily_vol_transported <= 1e-6: continue\n",
    "        pattern_requires_volume = True\n",
    "\n",
    "        if up_id not in current_up_status.index:\n",
    "             print(f\"  ERROR: UP {up_id} from pattern not in current_up_status index.\")\n",
    "             return 0 # Cannot extend\n",
    "\n",
    "        vol_restante = current_up_status.loc[up_id, 'VOLUME_RESTANTE']\n",
    "\n",
    "        # Check if UP required by pattern is already depleted\n",
    "        if vol_restante <= 1e-6:\n",
    "             # print(f\"  WARN: UP {up_id} required by pattern has 0 volume. Cannot apply.\") # Reduce verbosity\n",
    "             return 0 # Cannot apply pattern even once\n",
    "\n",
    "        # Avoid division by zero (already checked daily_vol_transported)\n",
    "        days_possible_for_up = math.floor(vol_restante / daily_vol_transported)\n",
    "        max_k = min(max_k, days_possible_for_up)\n",
    "\n",
    "    # If no UP required volume (e.g., pattern only moves from already full UPs? Unlikely)\n",
    "    if not pattern_requires_volume:\n",
    "         max_k = 1 # Should be handled by initial check, but defensively set to 1\n",
    "\n",
    "    days_left_in_horizon = horizon_end_day - current_day + 1\n",
    "    max_k = min(max_k, days_left_in_horizon)\n",
    "\n",
    "    if max_k == float('inf'):\n",
    "        return min(1, days_left_in_horizon) # Should not happen if logic above is correct\n",
    "    else:\n",
    "        # If max_k calculation resulted in 0, it means less than 1 day's volume is available.\n",
    "        # Since we passed the vol_restante check, we can apply it once.\n",
    "        final_k = max(0, int(max_k))\n",
    "        if final_k == 0 and pattern_requires_volume:\n",
    "             final_k = 1 # Allow running for the current day\n",
    "        final_k = min(final_k, days_left_in_horizon) # Ensure not exceeding horizon\n",
    "        return final_k\n",
    "\n",
    "\n",
    "# --- Main Control Loop for Pattern Heuristic ---\n",
    "def run_pattern_based_heuristic(df_horizonte, df_bd_up, df_frota, df_grua, df_fabrica, df_rota, max_daily_attempts=100):\n",
    "    \"\"\"\n",
    "    Orchestrates the pattern-finding and extension heuristic.\n",
    "    Attempts to generate schedule entries for all days, using best-effort for failed days.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Pattern-Based Heuristic (Generating entries for ALL days) ---\")\n",
    "    overall_schedule_list = []\n",
    "    if 'DIA' not in df_horizonte.columns: print(\"ERROR: 'DIA' missing in df_horizonte.\"); return None\n",
    "    current_day = df_horizonte['DIA'].min()\n",
    "    horizon_end_day = df_horizonte['DIA'].max()\n",
    "\n",
    "    if 'UP' not in df_bd_up.columns: print(\"ERROR: 'UP' missing in df_bd_up.\"); return None\n",
    "    up_status = df_bd_up.set_index('UP').copy()\n",
    "    if 'VOLUME' not in up_status.columns: print(\"ERROR: 'VOLUME' missing in up_status.\"); return None\n",
    "\n",
    "    up_status['VOLUME_RESTANTE'] = up_status['VOLUME']\n",
    "    up_status['DIAS_TRABAJADOS'] = [[] for _ in range(len(up_status))]\n",
    "    up_status['BLOQUES_TRABAJO'] = 0\n",
    "    up_status['ESTADO'] = 'PENDIENTE'\n",
    "\n",
    "    while current_day <= horizon_end_day:\n",
    "        print(f\"\\nProcessing Day {current_day}...\")\n",
    "\n",
    "        # 1. Try find a feasible pattern. Also get the pattern itself (even if infeasible).\n",
    "        daily_pattern, is_pattern_feasible = find_feasible_daily_pattern(\n",
    "            current_day, up_status, df_horizonte, df_frota, df_grua, df_fabrica, df_rota, max_daily_attempts\n",
    "        )\n",
    "\n",
    "        # If constructive heuristic failed entirely (returned None)\n",
    "        if daily_pattern is None:\n",
    "             print(f\"  ERROR: Constructive heuristic failed completely for Day {current_day}. Skipping day.\")\n",
    "             current_day += 1\n",
    "             continue\n",
    "\n",
    "        # If a pattern was generated (feasible or not)\n",
    "        k = 0 # Default extension days\n",
    "        if is_pattern_feasible:\n",
    "             # If the pattern found is feasible, calculate extension days\n",
    "             k = calculate_extension_days(daily_pattern, up_status, horizon_end_day, current_day)\n",
    "             if k == 0:\n",
    "                  print(f\"  WARN: Feasible pattern for Day {current_day} cannot be applied (k=0, UP depleted?). Applying for 1 day only.\")\n",
    "                  k = 1 # Force applying the feasible pattern once\n",
    "             else:\n",
    "                  print(f\"  Feasible pattern found Day {current_day}. Extending for {k} day(s).\")\n",
    "        else:\n",
    "             # If the pattern found was infeasible (best effort from find_feasible_daily_pattern)\n",
    "             print(f\"  WARN: Using infeasible best-effort pattern for Day {current_day}. Applying for 1 day only.\")\n",
    "             k = 1 # Apply the infeasible pattern only for the current day\n",
    "\n",
    "        # Ensure k doesn't push beyond horizon\n",
    "        k = min(k, horizon_end_day - current_day + 1)\n",
    "\n",
    "        # Apply the pattern (feasible or infeasible) for k days and update state\n",
    "        for i in range(k):\n",
    "            day_to_apply = current_day + i\n",
    "            if day_to_apply > horizon_end_day: break\n",
    "\n",
    "            # Ensure daily_pattern is a DataFrame before copying\n",
    "            if not isinstance(daily_pattern, pd.DataFrame):\n",
    "                print(f\"ERROR: daily_pattern for day {current_day} is not a DataFrame. Skipping application.\")\n",
    "                # This case should ideally not happen if find_feasible_daily_pattern returns correctly\n",
    "                break # Break from the inner loop for this pattern\n",
    "\n",
    "            pattern_copy = daily_pattern.copy()\n",
    "            # Ensure pattern_copy is not empty before proceeding\n",
    "            if pattern_copy.empty:\n",
    "                 print(f\"  INFO: Applying empty pattern for Day {day_to_apply}.\")\n",
    "                 # Add an empty df placeholder? Or just skip adding? Let's skip adding for now.\n",
    "                 # overall_schedule_list.append(pattern_copy) # Avoid adding empty dfs\n",
    "            else:\n",
    "                 pattern_copy['DIA'] = day_to_apply\n",
    "                 day_horizon_info = df_horizonte[df_horizonte['DIA'] == day_to_apply]\n",
    "                 if not day_horizon_info.empty:\n",
    "                      pattern_copy['MES'] = day_horizon_info['MES'].iloc[0] if 'MES' in day_horizon_info.columns else None\n",
    "                 overall_schedule_list.append(pattern_copy) # Add the schedule entries\n",
    "\n",
    "                 # Update state only if the pattern wasn't empty\n",
    "                 if 'UP' not in pattern_copy.columns or 'VOLUME' not in pattern_copy.columns:\n",
    "                      print(f\"ERROR: Pattern copy day {day_to_apply} missing UP/VOLUME.\")\n",
    "                      continue\n",
    "\n",
    "                 volume_transported_today = pattern_copy.groupby('UP')['VOLUME'].sum()\n",
    "                 for up_id, vol_transported in volume_transported_today.items():\n",
    "                     if up_id not in up_status.index: continue\n",
    "                     if vol_transported > 1e-6:\n",
    "                         try:\n",
    "                             up_status.loc[up_id, 'VOLUME_RESTANTE'] -= vol_transported\n",
    "                             if up_status.loc[up_id, 'VOLUME_RESTANTE'] < 0: up_status.loc[up_id, 'VOLUME_RESTANTE'] = 0\n",
    "                             dias_list = up_status.at[up_id, 'DIAS_TRABAJADOS']\n",
    "                             if not isinstance(dias_list, list): dias_list = []\n",
    "                             last_day_worked = dias_list[-1] if dias_list else None\n",
    "                             is_new_block = False\n",
    "                             if last_day_worked is None: is_new_block = True\n",
    "                             elif isinstance(last_day_worked, (int, float)) and day_to_apply != last_day_worked + 1:\n",
    "                                 is_new_block = True\n",
    "                                 if pd.isna(up_status.at[up_id, 'BLOQUES_TRABAJO']): up_status.at[up_id, 'BLOQUES_TRABAJO'] = 0\n",
    "                                 if last_day_worked is not None:\n",
    "                                     up_status.at[up_id, 'BLOQUES_TRABAJO'] += 1\n",
    "                             if day_to_apply not in dias_list:\n",
    "                                  dias_list.append(day_to_apply)\n",
    "                                  up_status.at[up_id, 'DIAS_TRABAJADOS'] = dias_list\n",
    "                             if up_status.loc[up_id, 'VOLUME_RESTANTE'] <= 1e-6: up_status.loc[up_id, 'ESTADO'] = 'COMPLETADA'\n",
    "                             else: up_status.loc[up_id, 'ESTADO'] = 'ACTIVA'\n",
    "                         except KeyError: print(f\"ERROR: KeyError updating state {up_id}.\"); continue\n",
    "                         except Exception as e: print(f\"ERROR: Update state {up_id} day {day_to_apply}: {e}\"); continue\n",
    "\n",
    "        # Advance the current day by the number of days the pattern was applied\n",
    "        # Ensure k is at least 1 if we applied something\n",
    "        current_day += max(1, k) # Advance by at least 1 day\n",
    "\n",
    "    print(\"\\n--- Pattern-Based Heuristic Finished (Attempted all days) ---\")\n",
    "    if not overall_schedule_list: return pd.DataFrame()\n",
    "    try: final_schedule = pd.concat(overall_schedule_list, ignore_index=True)\n",
    "    except Exception as e: print(f\"ERROR: Concat final schedule: {e}\"); return None\n",
    "\n",
    "    print(\"\\nValidating the complete generated schedule...\")\n",
    "    try:\n",
    "        # Ensure validate_all_constraints is defined\n",
    "        # Pass flag=0 to suppress validation prints unless needed\n",
    "        is_final_feasible = validate_essential_constraints(final_schedule, df_fabrica, df_frota, df_grua, df_bd_up, flag=0)\n",
    "        if is_final_feasible: print(\">>> Final Schedule is Feasible <<<\")\n",
    "        else: print(\">>> FINAL SCHEDULE IS INFEASIBLE (As expected potentially, due to forced daily entries) <<<\")\n",
    "    except NameError: print(\"WARNING: `validate_all_constraints` not defined.\")\n",
    "    except Exception as e: print(f\"ERROR: Final validation: {e}\")\n",
    "    return final_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffdfe342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Pattern-Based Heuristic (Generating entries for ALL days) ---\n",
      "\n",
      "Processing Day 1...\n",
      "  Feasible pattern found Day 1. Extending for 4 day(s).\n",
      "\n",
      "Processing Day 5...\n",
      "  Feasible pattern found Day 5. Extending for 2 day(s).\n",
      "\n",
      "Processing Day 7...\n",
      "  Feasible pattern found Day 7. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 8...\n",
      "  Feasible pattern found Day 8. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 9...\n",
      "  WARN: Feasible pattern for Day 9 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 10...\n",
      "  WARN: Feasible pattern for Day 10 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 11...\n",
      "  WARN: Feasible pattern for Day 11 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 12...\n",
      "  WARN: Feasible pattern for Day 12 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 13...\n",
      "  WARN: Feasible pattern for Day 13 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 14...\n",
      "  WARN: Feasible pattern for Day 14 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 15...\n",
      "  Feasible pattern found Day 15. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 16...\n",
      "  Feasible pattern found Day 16. Extending for 2 day(s).\n",
      "\n",
      "Processing Day 18...\n",
      "  WARN: Feasible pattern for Day 18 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 19...\n",
      "  WARN: Feasible pattern for Day 19 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 20...\n",
      "  WARN: Feasible pattern for Day 20 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 21...\n",
      "  Feasible pattern found Day 21. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 22...\n",
      "  WARN: Feasible pattern for Day 22 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 23...\n",
      "  WARN: Feasible pattern for Day 23 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 24...\n",
      "  WARN: Feasible pattern for Day 24 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 25...\n",
      "  WARN: Feasible pattern for Day 25 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 26...\n",
      "  WARN: Feasible pattern for Day 26 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 27...\n",
      "  WARN: Feasible pattern for Day 27 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 28...\n",
      "  WARN: Feasible pattern for Day 28 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 29...\n",
      "  WARN: Feasible pattern for Day 29 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 30...\n",
      "  WARN: Feasible pattern for Day 30 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 31...\n",
      "  WARN: Feasible pattern for Day 31 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "--- Pattern-Based Heuristic Finished (Attempted all days) ---\n",
      "\n",
      "Validating the complete generated schedule...\n",
      ">>> Final Schedule is Feasible <<<\n",
      "         UP                      FAZENDA TRANSPORTADOR  DIA  MES          DB  \\\n",
      "0    S5AK05              TURVO III (LEX)       Pastori    1    5  493.203247   \n",
      "1    S5AK09              TURVO III (LEX)       Pastori    1    5  485.001740   \n",
      "2    S5AW10  PIRACEMA_GLEBA PULADOR - DX       Rampazo    1    5  489.657814   \n",
      "3    S5AW05  PIRACEMA_GLEBA PULADOR - DX       Rampazo    1    5  450.000000   \n",
      "4    S6C335                    FORTALEZA         Tover    1    5  462.157496   \n",
      "..      ...                          ...           ...  ...  ...         ...   \n",
      "145  S6BX01         SANTO ANTONIO SALIG.         Tover   31    5  450.000000   \n",
      "146  S3AX03                   INDIANA II       Rampazo   31    5  410.081889   \n",
      "147  S3AX06                   INDIANA II       Rampazo   31    5  473.890188   \n",
      "148  S5AW09  PIRACEMA_GLEBA PULADOR - DX       Pastori   31    5  485.300233   \n",
      "149  S5AW05  PIRACEMA_GLEBA PULADOR - DX       Pastori   31    5  450.000000   \n",
      "\n",
      "          RSP  QTD_VEICULOS  VOLUME  RSP_WEIGHTED_SUM  \n",
      "0    1.479045            13  1201.2       1776.628713  \n",
      "1    1.513740            14  1293.6       1958.173482  \n",
      "2    1.441440             9   891.0       1284.322843  \n",
      "3    1.440000            12  1188.0       1710.720000  \n",
      "4    1.519874            14  1940.4       2949.163678  \n",
      "..        ...           ...     ...               ...  \n",
      "145  1.440000            14  2032.8       2927.232000  \n",
      "146  1.302226             9  1069.2       1392.340204  \n",
      "147  1.550207            12  1425.6       2209.974977  \n",
      "148  1.403137            11  1089.0       1528.015785  \n",
      "149  1.440000            16  1584.0       2280.960000  \n",
      "\n",
      "[150 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "flag=0\n",
    "# Run the pattern-based approach\n",
    "df_horizonte1=df_horizonte#.iloc[0:15]\n",
    "df_fabrica1=df_fabrica#.iloc[0:15]\n",
    "\n",
    "# 1. Run the pattern-based heuristic to get an initial FEASIBLE solution\n",
    "initial_feasible_solution = run_pattern_based_heuristic(df_horizonte, df_bd_up, df_frota, df_grua, df_fabrica, df_rota, max_daily_attempts=200)\n",
    "print(initial_feasible_solution)\n",
    "initial_feasible_solution.to_csv(\"pattern_heuristic_partial_solution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff2ed922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Objective Function ---\n",
    "def calculate_objective(schedule_df):\n",
    "    \"\"\"\n",
    "    Calculates the average of daily DB variation (DB_max - DB_min).\n",
    "\n",
    "    Args:\n",
    "        schedule_df (pd.DataFrame): A complete schedule DataFrame with 'DIA' and 'DB' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: The total DB variation over the horizon, or float('inf') if schedule is empty/invalid.\n",
    "    \"\"\"\n",
    "    if schedule_df is None or schedule_df.empty or 'DIA' not in schedule_df.columns or 'DB' not in schedule_df.columns:\n",
    "        return float('inf') # Cannot calculate objective for invalid input\n",
    "\n",
    "    total_variation = 0\n",
    "    # Group by day and calculate DB range for each day\n",
    "    for day, group in schedule_df.groupby('DIA'):\n",
    "        if not group.empty:\n",
    "            db_max = group['DB'].max()\n",
    "            db_min = group['DB'].min()\n",
    "            total_variation += (db_max - db_min)\n",
    "        # If a day has no deliveries, its variation is 0, so no need to add anything\n",
    "\n",
    "    return total_variation/len(schedule_df.groupby('DIA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40667cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.91748356239294\n"
     ]
    }
   ],
   "source": [
    "result=calculate_objective(initial_feasible_solution)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4fc1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Neighborhood Search (Simulated Annealing Example) ---\n",
    "\n",
    "# --- Neighborhood Move Functions ---\n",
    "def move_change_vehicles(current_schedule, df_rota, df_frota):\n",
    "    \"\"\"\n",
    "    Attempts to change the number of vehicles for a randomly chosen task.\n",
    "    Tries to maintain transporter fleet limits but doesn't guarantee overall feasibility.\n",
    "    \"\"\"\n",
    "    if current_schedule.empty: return current_schedule.copy()\n",
    "\n",
    "    neighbor_schedule = current_schedule.copy()\n",
    "    try:\n",
    "        task_index = random.choice(neighbor_schedule.index)\n",
    "    except IndexError:\n",
    "        print(\"WARN (move): Cannot choose task from empty schedule.\")\n",
    "        return neighbor_schedule\n",
    "\n",
    "    task = neighbor_schedule.loc[task_index]\n",
    "    required_task_cols = ['TRANSPORTADOR', 'DIA', 'UP', 'QTD_VEICULOS', 'VOLUME']\n",
    "    if not all(col in task for col in required_task_cols):\n",
    "        print(f\"WARN (move): Task at index {task_index} missing required columns. Skipping move.\")\n",
    "        return neighbor_schedule\n",
    "\n",
    "    transportador = task['TRANSPORTADOR']\n",
    "    day = task['DIA']\n",
    "    up_id = task['UP']\n",
    "\n",
    "    try:\n",
    "        frota_info = df_frota[df_frota['TRANSPORTADOR'] == transportador].iloc[0]\n",
    "        frota_min = frota_info['FROTA_MIN']\n",
    "        frota_max = frota_info['FROTA_MAX']\n",
    "    except IndexError:\n",
    "        print(f\"WARN (move): Frota info not found for {transportador}\")\n",
    "        return neighbor_schedule\n",
    "\n",
    "    if 'QTD_VEICULOS' not in neighbor_schedule.columns:\n",
    "        print(f\"WARN (move): QTD_VEICULOS column missing in schedule. Cannot check fleet size.\")\n",
    "        return neighbor_schedule\n",
    "\n",
    "    current_total_vehicles = neighbor_schedule[\n",
    "        (neighbor_schedule['DIA'] == day) &\n",
    "        (neighbor_schedule['TRANSPORTADOR'] == transportador)\n",
    "    ]['QTD_VEICULOS'].sum()\n",
    "\n",
    "    change = random.choice([-1, 1])\n",
    "    new_vehicle_count = task['QTD_VEICULOS'] + change\n",
    "    if new_vehicle_count <= 0: new_vehicle_count = 1\n",
    "\n",
    "    new_total_vehicles = current_total_vehicles - task['QTD_VEICULOS'] + new_vehicle_count\n",
    "    if not (frota_min <= new_total_vehicles <= frota_max):\n",
    "        return neighbor_schedule # Skip move\n",
    "\n",
    "    neighbor_schedule.loc[task_index, 'QTD_VEICULOS'] = new_vehicle_count\n",
    "\n",
    "    # --- SIMPLIFICATION for Volume Recalculation ---\n",
    "    # Volume is NOT recalculated here. Feasibility check handles consequences.\n",
    "\n",
    "    return neighbor_schedule\n",
    "\n",
    "# Add more move functions (e.g., reassign_transporter, shift_volume) - more complex\n",
    "\n",
    "# --- Simulated Annealing Main Function ---\n",
    "def simulated_annealing(initial_schedule, df_fabrica, df_frota, df_grua, df_bd_up, df_rota,\n",
    "                        initial_temp=100, cooling_rate=0.99, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Performs Simulated Annealing to optimize the schedule based on DB variation.\n",
    "    Assumes initial_schedule is FEASIBLE.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Simulated Annealing Optimization ---\")\n",
    "    try:\n",
    "        if not validate_essential_constraints(initial_schedule, df_fabrica, df_frota, df_grua, df_bd_up,flag):\n",
    "            print(\"ERROR: Initial schedule for SA is infeasible. Aborting optimization.\")\n",
    "            return initial_schedule\n",
    "    except NameError:\n",
    "        print(\"ERROR: `validate_essential_constraints` not defined. Cannot verify initial schedule for SA.\")\n",
    "        return initial_schedule\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Exception during initial validation for SA: {e}\")\n",
    "        return initial_schedule\n",
    "\n",
    "    current_schedule = initial_schedule.copy()\n",
    "    current_objective = calculate_objective(current_schedule)\n",
    "    best_schedule = current_schedule.copy()\n",
    "    best_objective = current_objective\n",
    "    temperature = initial_temp\n",
    "\n",
    "    print(f\"Initial Objective (DB Variation): {current_objective:.2f}\")\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        if temperature < 1e-3: break\n",
    "\n",
    "        try:\n",
    "            move_function = random.choice([move_change_vehicles])\n",
    "            neighbor_schedule = move_function(current_schedule, df_rota, df_frota)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR generating neighbor in iteration {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            is_neighbor_feasible = validate_essential_constraints(neighbor_schedule, df_fabrica, df_frota, df_grua, df_bd_up,flag)\n",
    "        except NameError:\n",
    "            print(\"ERROR: `validate_essential_constraints` not defined. Cannot run SA.\")\n",
    "            return best_schedule\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR validating neighbor in iteration {i+1}: {e}\")\n",
    "            is_neighbor_feasible = False\n",
    "\n",
    "        if is_neighbor_feasible:\n",
    "            neighbor_objective = calculate_objective(neighbor_schedule)\n",
    "            delta_objective = neighbor_objective - current_objective\n",
    "            accept = False\n",
    "            if delta_objective < 0: accept = True\n",
    "            else:\n",
    "                if temperature > 1e-9:\n",
    "                    try:\n",
    "                        acceptance_prob = math.exp(-delta_objective / temperature)\n",
    "                        if random.random() < acceptance_prob: accept = True\n",
    "                    except OverflowError: accept = False\n",
    "            if accept:\n",
    "                current_schedule = neighbor_schedule.copy()\n",
    "                current_objective = neighbor_objective\n",
    "                if current_objective < best_objective:\n",
    "                    best_schedule = current_schedule.copy()\n",
    "                    best_objective = current_objective\n",
    "\n",
    "        temperature *= cooling_rate\n",
    "        if (i + 1) % 100 == 0:\n",
    "             print(f\"  SA Iteration {i+1}/{max_iterations}, Temp: {temperature:.2f}, Current Obj: {current_objective:.2f}, Best Obj: {best_objective:.2f}\")\n",
    "\n",
    "    print(f\"--- Simulated Annealing Finished ---\")\n",
    "    print(f\"Final Best Objective (DB Variation): {best_objective:.2f}\")\n",
    "    return best_schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51c958ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Pattern-Based Heuristic (Generating entries for ALL days) ---\n",
      "\n",
      "Processing Day 1...\n",
      "  Feasible pattern found Day 1. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 2...\n",
      "  Feasible pattern found Day 2. Extending for 5 day(s).\n",
      "\n",
      "Processing Day 7...\n",
      "  Feasible pattern found Day 7. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 8...\n",
      "  Feasible pattern found Day 8. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 9...\n",
      "  Feasible pattern found Day 9. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 10...\n",
      "  Feasible pattern found Day 10. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 11...\n",
      "  WARN: Feasible pattern for Day 11 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 12...\n",
      "  WARN: Feasible pattern for Day 12 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 13...\n",
      "  WARN: Feasible pattern for Day 13 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 14...\n",
      "  WARN: Feasible pattern for Day 14 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 15...\n",
      "  Feasible pattern found Day 15. Extending for 1 day(s).\n",
      "\n",
      "Processing Day 16...\n",
      "  WARN: Feasible pattern for Day 16 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 17...\n",
      "  WARN: Feasible pattern for Day 17 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 18...\n",
      "  WARN: Feasible pattern for Day 18 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 19...\n",
      "  WARN: Feasible pattern for Day 19 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 20...\n",
      "  WARN: Feasible pattern for Day 20 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 21...\n",
      "  WARN: Feasible pattern for Day 21 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 22...\n",
      "  WARN: Feasible pattern for Day 22 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 23...\n",
      "  WARN: Feasible pattern for Day 23 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 24...\n",
      "  WARN: Feasible pattern for Day 24 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 25...\n",
      "  WARN: Feasible pattern for Day 25 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 26...\n",
      "  WARN: Feasible pattern for Day 26 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 27...\n",
      "  WARN: Feasible pattern for Day 27 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 28...\n",
      "  WARN: Feasible pattern for Day 28 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 29...\n",
      "  WARN: Feasible pattern for Day 29 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 30...\n",
      "  WARN: Feasible pattern for Day 30 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "Processing Day 31...\n",
      "  WARN: Feasible pattern for Day 31 cannot be applied (k=0, UP depleted?). Applying for 1 day only.\n",
      "\n",
      "--- Pattern-Based Heuristic Finished (Attempted all days) ---\n",
      "\n",
      "Validating the complete generated schedule...\n",
      ">>> Final Schedule is Feasible <<<\n",
      "\n",
      "Initial feasible solution found by pattern heuristic. Proceeding to SA optimization.\n",
      "\n",
      "--- Starting Simulated Annealing Optimization ---\n",
      "Initial Objective (DB Variation): 54.98\n",
      "  SA Iteration 100/2000, Temp: 36.60, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 200/2000, Temp: 13.40, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 300/2000, Temp: 4.90, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 400/2000, Temp: 1.80, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 500/2000, Temp: 0.66, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 600/2000, Temp: 0.24, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 700/2000, Temp: 0.09, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 800/2000, Temp: 0.03, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 900/2000, Temp: 0.01, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 1000/2000, Temp: 0.00, Current Obj: 54.98, Best Obj: 54.98\n",
      "  SA Iteration 1100/2000, Temp: 0.00, Current Obj: 54.98, Best Obj: 54.98\n",
      "--- Simulated Annealing Finished ---\n",
      "Final Best Objective (DB Variation): 54.98\n",
      "\n",
      "--- Optimized Schedule ---\n",
      "         UP                      FAZENDA TRANSPORTADOR  DIA  MES          DB  \\\n",
      "0    S5AW09  PIRACEMA_GLEBA PULADOR - DX       Rampazo    1    5  485.300233   \n",
      "1    S5AW14  PIRACEMA_GLEBA PULADOR - DX       Rampazo    1    5  467.553351   \n",
      "2    S6BG08                      SINIMBU         Tover    1    5  477.261800   \n",
      "3    S5AK08              TURVO III (LEX)       Pastori    1    5  484.253826   \n",
      "4    S5AW10  PIRACEMA_GLEBA PULADOR - DX       Pastori    2    5  489.657814   \n",
      "..      ...                          ...           ...  ...  ...         ...   \n",
      "138  S3AX06                   INDIANA II       Pastori   30    5  473.890188   \n",
      "139  S6BX01         SANTO ANTONIO SALIG.         Tover   30    5  450.000000   \n",
      "140  S6C421                      SIRIEMA         Tover   31    5  406.666302   \n",
      "141  S5AW09  PIRACEMA_GLEBA PULADOR - DX       Rampazo   31    5  485.300233   \n",
      "142  S5AK08              TURVO III (LEX)       Pastori   31    5  484.253826   \n",
      "\n",
      "          RSP  QTD_VEICULOS  VOLUME  RSP_WEIGHTED_SUM  \n",
      "0    1.403137            12  1188.0       1666.926311  \n",
      "1    1.378530             9   891.0       1228.270499  \n",
      "2    1.534662            14  1960.0       3007.937779  \n",
      "3    1.515094            27  2494.8       3779.855773  \n",
      "4    1.441440            11  1089.0       1569.727920  \n",
      "..        ...           ...     ...               ...  \n",
      "138  1.550207            27  3207.6       4972.443698  \n",
      "139  1.440000            14  2032.8       2927.232000  \n",
      "140  1.289003            14  2310.0       2977.596313  \n",
      "141  1.403137            21  2079.0       2917.121044  \n",
      "142  1.515094            27  2494.8       3779.855773  \n",
      "\n",
      "[143 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "flag=0\n",
    "# Run the pattern-based approach\n",
    "df_horizonte1=df_horizonte#.iloc[0:15]\n",
    "df_fabrica1=df_fabrica#.iloc[0:15]\n",
    "\n",
    "# 1. Run the pattern-based heuristic to get an initial FEASIBLE solution\n",
    "initial_feasible_solution = run_pattern_based_heuristic(df_horizonte, df_bd_up, df_frota, df_grua, df_fabrica, df_rota, max_daily_attempts=200)\n",
    "\n",
    "# 2. Check if the initial solution is feasible and not None/Empty\n",
    "# Need to ensure validate_essential_constraints is defined\n",
    "is_initial_feasible = False\n",
    "if initial_feasible_solution is not None and not initial_feasible_solution.empty:\n",
    "    try:\n",
    "        # Ensure validate_essential_constraints is defined and callable\n",
    "        if 'validate_essential_constraints' in globals() and callable(globals()['validate_essential_constraints']):\n",
    "             if validate_essential_constraints(initial_feasible_solution, df_fabrica, df_frota, df_grua, df_bd_up,flag):\n",
    "                  is_initial_feasible = True\n",
    "        else:\n",
    "             print(\"WARNING: `validate_essential_constraints` function not found or not callable.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR validating initial solution: {e}\")\n",
    "\n",
    "\n",
    "if is_initial_feasible:\n",
    "    print(\"\\nInitial feasible solution found by pattern heuristic. Proceeding to SA optimization.\")\n",
    "\n",
    "    # 3. Run Simulated Annealing to optimize the feasible solution\n",
    "    optimized_solution = simulated_annealing(\n",
    "        initial_schedule=initial_feasible_solution,\n",
    "        df_fabrica=df_fabrica,\n",
    "        df_frota=df_frota,\n",
    "        df_grua=df_grua,\n",
    "        df_bd_up=df_bd_up, # Needed for validation inside SA\n",
    "        df_rota=df_rota,   # Needed for moves like change_vehicles\n",
    "        initial_temp=100,  # Tune these parameters\n",
    "        cooling_rate=0.99, # Tune these parameters\n",
    "        max_iterations=2000 # Tune these parameters\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Optimized Schedule ---\")\n",
    "    print(optimized_solution)\n",
    "    # Optional: Save the optimized solution\n",
    "    # optimized_solution.to_csv(\"optimized_sa_solution.csv\", index=False)\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- Pattern heuristic did not produce a feasible initial solution. Cannot run SA optimization. ---\")\n",
    "    if initial_feasible_solution is not None:\n",
    "        print(\"Final (partial or infeasible) schedule from pattern heuristic:\")\n",
    "        print(initial_feasible_solution)\n",
    "        # Optional: Save the partial/infeasible solution for analysis\n",
    "        # initial_feasible_solution.to_csv(\"pattern_heuristic_partial_solution.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
